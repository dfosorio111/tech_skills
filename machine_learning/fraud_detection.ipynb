{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e6d2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0009944438934326172 seconds ---\n"
     ]
    }
   ],
   "source": [
    "### importar librerias\n",
    "# importar librerias tratamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import warnings\n",
    "import math as m\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import time\n",
    "tiempo=time.time()\n",
    "\n",
    "\n",
    "# librerias pre-procesamiento\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, RobustScaler, PowerTransformer, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE, KMeansSMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# librerias para modelos \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# metricas de evaluacion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268bbd0",
   "metadata": {},
   "source": [
    "# Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817d4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para estandarizar las variables continuas\n",
    "def estandarizacion(df):\n",
    "    return df.apply(lambda x: (x-x.mean())/x.std(), axis=0)\n",
    "\n",
    "# Cálculo de IV #Tomada del material del curso Machine Learning Profesor Fernando Lozano.\n",
    "def calc_iv(df, feature, target, pr=False):\n",
    "    lst = []\n",
    "    df[feature] = df[feature].fillna(\"NULL\")\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature,                                                        # Variable\n",
    "                    val,                                                            # Value\n",
    "                    df[df[feature] == val].count()[feature],                        # All\n",
    "                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # Good (think: Fraud == 0)\n",
    "                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]]) # Bad (think: Fraud == 1)\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "    \n",
    "    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "\n",
    "    data['IV'] = data['WoE'] * (data['Distribution Good'] - data['Distribution Bad'])\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=[True, True])\n",
    "    data.index = range(len(data.index))\n",
    "\n",
    "    if pr:\n",
    "        print(data)\n",
    "        print('IV = ', data['IV'].sum())\n",
    "\n",
    "    iv = data['IV'].sum()\n",
    "    print('El IV de esta variable es:',iv)\n",
    "    print(df[feature].value_counts())\n",
    "    return iv, data\n",
    "\n",
    "# Matriz de Confusión  #Tomada del material del curso Machine Learning Profesor Fernando Lozano.\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta')\n",
    "    plt.xlabel('Predicción')\n",
    "    \n",
    "# Codificación One-Hot #Tomada del material del curso Machine Learning Profesor Fernando Lozano.\n",
    "def convert_dummy(df, feature,rank=0):\n",
    "    pos = pd.get_dummies(df[feature], prefix=feature)\n",
    "    mode = df[feature].value_counts().index[rank]\n",
    "    biggest = feature + '_' + str(mode)\n",
    "    pos.drop([biggest],axis=1,inplace=True)\n",
    "    df.drop([feature],axis=1,inplace=True)\n",
    "    df=df.join(pos)\n",
    "    return df\n",
    "\n",
    "def convert_dummy2(df):\n",
    "    df = pd.get_dummies(df, drop_first=False)\n",
    "    return df\n",
    "\n",
    "#Tomada del material del curso Machine Learning Profesor Fernando Lozano.\n",
    "def get_category(df, col, binsnum, labels, prefijo, qcut = False):\n",
    "    if qcut:\n",
    "        localdf = pd.qcut(df[col], q = binsnum, labels = labels) # quantile cut\n",
    "    else:\n",
    "        localdf = pd.cut(df[col], bins = binsnum, labels = labels) # equal-length cut\n",
    "        \n",
    "    localdf = pd.DataFrame(localdf)\n",
    "    name = prefijo + '_' + col\n",
    "    localdf[name] = localdf[col]\n",
    "    df = df.join(localdf[name])\n",
    "    df[name] = df[name].astype(object)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca59b65",
   "metadata": {},
   "source": [
    "#  Cargar bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f079cbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.996580</td>\n",
       "      <td>-0.694241</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672771</td>\n",
       "      <td>0.973364</td>\n",
       "      <td>-0.245116</td>\n",
       "      <td>0.347067</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330891</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.996580</td>\n",
       "      <td>0.608495</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316522</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307376</td>\n",
       "      <td>-0.880075</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561130</td>\n",
       "      <td>0.320693</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>-0.342474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.996558</td>\n",
       "      <td>-0.693499</td>\n",
       "      <td>-0.811576</td>\n",
       "      <td>1.169466</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364571</td>\n",
       "      <td>1.351451</td>\n",
       "      <td>0.639775</td>\n",
       "      <td>0.207372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337631</td>\n",
       "      <td>1.063356</td>\n",
       "      <td>1.456317</td>\n",
       "      <td>-1.138090</td>\n",
       "      <td>-0.628536</td>\n",
       "      <td>-0.288446</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.996558</td>\n",
       "      <td>-0.493324</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182514</td>\n",
       "      <td>-0.609726</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936148</td>\n",
       "      <td>0.192070</td>\n",
       "      <td>0.316017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304776</td>\n",
       "      <td>-1.941024</td>\n",
       "      <td>1.241902</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186188</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.996537</td>\n",
       "      <td>-0.591329</td>\n",
       "      <td>0.531540</td>\n",
       "      <td>1.021410</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071998</td>\n",
       "      <td>0.479301</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100009</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395201</td>\n",
       "      <td>1.041609</td>\n",
       "      <td>0.543619</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>284803</td>\n",
       "      <td>1.641929</td>\n",
       "      <td>-6.065831</td>\n",
       "      <td>6.099275</td>\n",
       "      <td>-6.486233</td>\n",
       "      <td>-1.459638</td>\n",
       "      <td>-3.886604</td>\n",
       "      <td>-1.956687</td>\n",
       "      <td>-3.975621</td>\n",
       "      <td>6.116562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290602</td>\n",
       "      <td>0.154146</td>\n",
       "      <td>1.624571</td>\n",
       "      <td>-0.840999</td>\n",
       "      <td>2.756316</td>\n",
       "      <td>0.518499</td>\n",
       "      <td>2.337897</td>\n",
       "      <td>2.495525</td>\n",
       "      <td>-0.350150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>284804</td>\n",
       "      <td>1.641950</td>\n",
       "      <td>-0.374121</td>\n",
       "      <td>-0.033356</td>\n",
       "      <td>1.342142</td>\n",
       "      <td>-0.521651</td>\n",
       "      <td>0.629039</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>0.246886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291625</td>\n",
       "      <td>1.273779</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>-1.677917</td>\n",
       "      <td>-1.163724</td>\n",
       "      <td>-0.819645</td>\n",
       "      <td>0.169641</td>\n",
       "      <td>-0.162163</td>\n",
       "      <td>-0.254116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>284805</td>\n",
       "      <td>1.641971</td>\n",
       "      <td>0.980022</td>\n",
       "      <td>-0.182433</td>\n",
       "      <td>-2.143201</td>\n",
       "      <td>-0.393983</td>\n",
       "      <td>1.905830</td>\n",
       "      <td>2.275258</td>\n",
       "      <td>-0.239939</td>\n",
       "      <td>0.593139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315912</td>\n",
       "      <td>0.796786</td>\n",
       "      <td>-0.060053</td>\n",
       "      <td>1.056942</td>\n",
       "      <td>0.509796</td>\n",
       "      <td>-0.181181</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>-0.080467</td>\n",
       "      <td>-0.081839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>284806</td>\n",
       "      <td>1.641971</td>\n",
       "      <td>-0.122755</td>\n",
       "      <td>0.321250</td>\n",
       "      <td>0.463319</td>\n",
       "      <td>0.487192</td>\n",
       "      <td>-0.273836</td>\n",
       "      <td>0.468154</td>\n",
       "      <td>-0.554671</td>\n",
       "      <td>0.568630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>1.102449</td>\n",
       "      <td>-0.261503</td>\n",
       "      <td>0.203427</td>\n",
       "      <td>-1.091853</td>\n",
       "      <td>1.133633</td>\n",
       "      <td>0.269604</td>\n",
       "      <td>0.316686</td>\n",
       "      <td>-0.313248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>284807</td>\n",
       "      <td>1.642055</td>\n",
       "      <td>-0.272330</td>\n",
       "      <td>-0.114899</td>\n",
       "      <td>0.463865</td>\n",
       "      <td>-0.357569</td>\n",
       "      <td>-0.009089</td>\n",
       "      <td>-0.487601</td>\n",
       "      <td>1.274767</td>\n",
       "      <td>-0.347176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355410</td>\n",
       "      <td>0.886147</td>\n",
       "      <td>0.603364</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>-0.908630</td>\n",
       "      <td>-1.696850</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      Time        V1        V2        V3        V4  \\\n",
       "0                1 -1.996580 -0.694241 -0.044075  1.672771  0.973364   \n",
       "1                2 -1.996580  0.608495  0.161176  0.109797  0.316522   \n",
       "2                3 -1.996558 -0.693499 -0.811576  1.169466  0.268231   \n",
       "3                4 -1.996558 -0.493324 -0.112169  1.182514 -0.609726   \n",
       "4                5 -1.996537 -0.591329  0.531540  1.021410  0.284655   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "284802      284803  1.641929 -6.065831  6.099275 -6.486233 -1.459638   \n",
       "284803      284804  1.641950 -0.374121 -0.033356  1.342142 -0.521651   \n",
       "284804      284805  1.641971  0.980022 -0.182433 -2.143201 -0.393983   \n",
       "284805      284806  1.641971 -0.122755  0.321250  0.463319  0.487192   \n",
       "284806      284807  1.642055 -0.272330 -0.114899  0.463865 -0.357569   \n",
       "\n",
       "              V5        V6        V7        V8  ...       V21       V22  \\\n",
       "0      -0.245116  0.347067  0.193679  0.082637  ... -0.024923  0.382854   \n",
       "1       0.043483 -0.061820 -0.063700  0.071253  ... -0.307376 -0.880075   \n",
       "2      -0.364571  1.351451  0.639775  0.207372  ...  0.337631  1.063356   \n",
       "3      -0.007469  0.936148  0.192070  0.316017  ... -0.147443  0.007267   \n",
       "4      -0.295015  0.071998  0.479301 -0.226510  ... -0.012839  1.100009   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -3.886604 -1.956687 -3.975621  6.116562  ...  0.290602  0.154146   \n",
       "284803  0.629039  0.794444  0.019667  0.246886  ...  0.291625  1.273779   \n",
       "284804  1.905830  2.275258 -0.239939  0.593139  ...  0.315912  0.796786   \n",
       "284805 -0.273836  0.468154 -0.554671  0.568630  ...  0.361111  1.102449   \n",
       "284806 -0.009089 -0.487601  1.274767 -0.347176  ...  0.355410  0.886147   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \\\n",
       "0      -0.176911  0.110507  0.246585 -0.392170  0.330891 -0.063781  0.244964   \n",
       "1       0.162201 -0.561130  0.320693  0.261069 -0.022256  0.044607 -0.342474   \n",
       "2       1.456317 -1.138090 -0.628536 -0.288446 -0.137137 -0.181021  1.160684   \n",
       "3      -0.304776 -1.941024  1.241902 -0.460217  0.155396  0.186188  0.140534   \n",
       "4      -0.220123  0.233250 -0.395201  1.041609  0.543619  0.651815 -0.073403   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.624571 -0.840999  2.756316  0.518499  2.337897  2.495525 -0.350150   \n",
       "284803  0.019958 -1.677917 -1.163724 -0.819645  0.169641 -0.162163 -0.254116   \n",
       "284804 -0.060053  1.056942  0.509796 -0.181181  0.011037 -0.080467 -0.081839   \n",
       "284805 -0.261503  0.203427 -1.091853  1.133633  0.269604  0.316686 -0.313248   \n",
       "284806  0.603364  0.014526 -0.908630 -1.696850 -0.005984  0.041350  0.514354   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se cargar bases de datos de fraude pre-procesada en R\n",
    "fraude_preprocess = pd.read_csv(\"data/fraude_preprocess.csv\")\n",
    "fraude_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1ac2dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separar predictores y variable objetivo\n",
    "\n",
    "X = fraude_preprocess.drop('Class', axis=1)\n",
    "y = fraude_preprocess['Class']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3b139d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "568625    1\n",
       "568626    1\n",
       "568627    1\n",
       "568628    1\n",
       "568629    1\n",
       "Name: Class, Length: 568630, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tecnicas de oversampling: caso extremo clase minoritaria menor a 1%\n",
    "\n",
    "smote = SMOTE(sampling_strategy= 0.4, n_jobs=-1,random_state = 100)\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X, y)\n",
    "y_resampled_smote\n",
    "\n",
    "adasyn = ADASYN(sampling_strategy = 'auto', n_jobs=-1, random_state=100)\n",
    "X_resampled_adasyn, y_resampled_adasyn = adasyn.fit_resample(X, y)\n",
    "y_resampled_adasyn\n",
    "\n",
    "borderline = BorderlineSMOTE(sampling_strategy = 'auto', n_jobs=-1, random_state=100)\n",
    "X_resampled_borderline, y_resampled_borderline = borderline.fit_resample(X, y)\n",
    "y_resampled_borderline\n",
    "\n",
    "svm_SMOTE = SVMSMOTE(sampling_strategy = 'auto', n_jobs=-1, random_state=100)\n",
    "X_resampled_svm_SMOTE, y_resampled_svm_SMOTE = svm_SMOTE.fit_resample(X, y)\n",
    "y_resampled_svm_SMOTE\n",
    "\n",
    "#kmeans_smote = KMeansSMOTE(sampling_strategy = 'auto', n_jobs=-1, random_state=100)\n",
    "#X_resampled_kmeans, y_resampled_kmeans = kmeans_smote.fit_resample(X, y)\n",
    "#y_resampled_kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b89633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train-set "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
