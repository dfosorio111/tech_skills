{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c43fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419040ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3: \n",
    "# Model Evaluation & Selection, Evaluation Metrics in ML\n",
    "# Evaluation metric: accuracy(score), precision, recall, F1\n",
    "\n",
    "# Dummy Classifiers \n",
    "# Confusion Matrix:  Binary Prediction Outcomes\n",
    "# Evaluation metrics for binary classification\n",
    "# Decision Functions (of probability)\n",
    "# Precision-Recall curves and ROC curves\n",
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc90cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3: Dummy Classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb23ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_binary_imbalanced = y.copy()\n",
    "# y_binary_imbalanced[y_binary_imbalanced != 1] = 0\n",
    "\n",
    "\n",
    "# dummy_majority = DummyClassifier(strategy = 'strategy').fit(X_train, y_train)\n",
    "\n",
    "# types of DummyClassifier strategy parameter:\n",
    "# most frequent: predicts most frequent label in train-set\n",
    "# stratified: random predictions based on train-set distribution of classes\n",
    "# uniform: predictions are uniformly at random\n",
    "# constant: always predicts the same label constant given by user\n",
    "\n",
    "# get confusion matrix \n",
    "# confusion = confusion_matrix(y_test, y_majority_predicted_from_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e11c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c8ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3: Dummy Classifiers\n",
    "# create DummyClassifier: DONT look at data-sets to do predictions\n",
    "# use strategy or rule-of-thumb\n",
    "# for inbalanced classification, dont use accuracy rather other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2f853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation & Selection\n",
    "# 1. choose evaluation methods that match the goal of application\n",
    "# 2. run evaluation metrics for multiple models\n",
    "# 3. select model with best value of evaluation from metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68bdd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = #correct predictions/#total predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12375f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 178\n",
      "1 182\n",
      "2 177\n",
      "3 183\n",
      "4 181\n",
      "5 182\n",
      "6 181\n",
      "7 179\n",
      "8 174\n",
      "9 180\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# load source data \n",
    "dataset = load_digits()\n",
    "\n",
    "# divide source data in X data and y target \n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "# get  data \n",
    "for class_name, class_count in zip(dataset.target_names, np.bincount(dataset.target)):\n",
    "    print(class_name,class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b881ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels:\t [1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n",
      "New binary labels:\t [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataset with imbalanced binary classes:  \n",
    "# Negative class (0) is 'not digit 1' \n",
    "# Positive class (1) is 'digit 1'\n",
    "\n",
    "# label digits, 0='not digit 1'  1='digit 1'\n",
    "y_binary_imbalanced = y.copy()\n",
    "y_binary_imbalanced[y_binary_imbalanced != 1] = 0\n",
    "\n",
    "print('Original labels:\\t', y[1:30])\n",
    "print('New binary labels:\\t', y_binary_imbalanced[1:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb5a971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1615,  182], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_binary_imbalanced)    # Negative class (0) is the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e43b468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9955555555555555"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide X, y data into train-set and test-set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
    "\n",
    "# Accuracy of Support Vector Machine classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# create SVectorMachine model, parameters: kernel function='rbf', C=1\n",
    "# fit/train model with train-set\n",
    "svm = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326a1b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# create DummyClassifier: DONT look at data-sets to do predictions\n",
    "# use strategy or rule-of-thumb\n",
    "# provides no accuracy base line, always picks most frequent class\n",
    "#  check on comparison, null comparison\n",
    "\n",
    "\n",
    "# Negative class (0) is most frequent\n",
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "\n",
    "# types of DummyClassifier strategy parameter:\n",
    "# most frequent: predicts most frequent label in train-set\n",
    "# stratified: random predictions based on train-set distribution of classes\n",
    "# uniform: predictions are uniformly at random\n",
    "# constant: always predicts the same label constant given by user\n",
    "\n",
    "\n",
    "\n",
    "# Therefore the dummy 'most_frequent' classifier always predicts class 0\n",
    "y_dummy_predictions = dummy_majority.predict(X_test)\n",
    "\n",
    "y_dummy_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad52fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044444444444445"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score/measure performance of DummyClassifier\n",
    "dummy_majority.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53c92d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed3abff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix outputs:  Binary Prediction Outcomes\n",
    "# output Negative: True negative TN, False positive FP\n",
    "# output Postive: False negative FN, True positive TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44562979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent class (dummy classifier)\n",
      " [[407   0]\n",
      " [ 43   0]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Negative class (0) is most frequent\n",
    "\n",
    "# create DummyClassifier, parameters:strategy = 'most_frequent', fit/train with train-set \n",
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "\n",
    "# dummy_majority.predict(X_test), most frequent majority predicted output\n",
    "# from X_test data\n",
    "y_majority_predicted = dummy_majority.predict(X_test)\n",
    "\n",
    "# get confusion matrix \n",
    "confusion = confusion_matrix(y_test, y_majority_predicted)\n",
    "\n",
    "print('Most frequent class (dummy classifier)\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2848e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0]\n",
      "Random class-proportional prediction (dummy classifier)\n",
      " [[361  46]\n",
      " [ 37   6]]\n"
     ]
    }
   ],
   "source": [
    "# produces random predictions w/ same class proportion as training set\n",
    "\n",
    "# create DummyClassifier, parameters:strategy='stratified'(random predictions based on train-set distribution of classes)\n",
    "dummy_classprop = DummyClassifier(strategy='stratified').fit(X_train, y_train)\n",
    "\n",
    "# get y target predicted by DummyClassifier, random predictions based on train-set classes distri\n",
    "# random output in proportion to ratio of labels in train-set\n",
    "\n",
    "\n",
    "\n",
    "y_classprop_predicted = dummy_classprop.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_classprop_predicted)\n",
    "print(y_classprop_predicted)\n",
    "print('Random class-proportional prediction (dummy classifier)\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec996dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 0]\n",
      "Support vector machine classifier (linear kernel, C=1)\n",
      " [[402   5]\n",
      " [  5  38]]\n"
     ]
    }
   ],
   "source": [
    "# create SVectorMachine model, parameters: kernel function='linear', C=1\n",
    "svm = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "svm_predicted = svm.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, svm_predicted)\n",
    "print(svm_predicted)\n",
    "print('Support vector machine classifier (linear kernel, C=1)\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fae119f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression classifier (default settings)\n",
      " [[401   6]\n",
      " [  8  35]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create LogisticRegression, standard default parameters\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "lr_predicted = lr.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, lr_predicted)\n",
    "\n",
    "print('Logistic regression classifier (default settings)\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d683292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree classifier (max_depth = 2)\n",
      " [[400   7]\n",
      " [ 17  26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create DecisionTreeClassifier model, parameters: max_depth=2 \n",
    "dt = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
    "tree_predicted = dt.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, tree_predicted)\n",
    "\n",
    "print('Decision tree classifier (max_depth = 2)\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7853958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3: Evaluation metrics for binary classification\n",
    "# Analysis Classification Performance\n",
    "\n",
    "# always look at the confusion matrix of the classifier model\n",
    "\n",
    "\n",
    "# Accuracy = (TN+TP)/(TOTAL): ratio of correct classifications to total\n",
    "# ClassificationError = (FP+FN)/(TOTAL) = 1-accuracy:  ratio of incorrect classifications to total\n",
    "# Recall = TruePositiveRate/Sensitivity/ProbDetection =  TP/(TP+FN): ratio of positive correct classifications to total TP+FN\n",
    "# Precision = TP/(TP+FP): ratio of true positive predictions to total positive predictions\n",
    "# FPR FalsePositiveRate/Specificity = FP/(TN+FP) ratio of false positive predictions to total negative predictions\n",
    "# F1 score = 2*(Precision*Recall)/(Precision+Recall)= 2TP/(2TP+FN+FP), combining precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "958ece9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy_score(y_test, y_model_predicted)\n",
    "# precision = precision_score(y_test, y_model_predicted)\n",
    "# recall = recall_score(y_test, y_model_predicted)\n",
    "# f1 score = f1_score(y_test, y_model_predicted)\n",
    "\n",
    "# classification_report(y_test, model_predicted, target_names= y_target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48bfe1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics Trade-offs: DEPENDS on the application of the model\n",
    "# High Precision- Low Recall: more true postive classifications of total positive predictions,\n",
    "# more true positive classifications predicted as negative(incorrectly classified)\n",
    "# narrow decision boundary\n",
    "# applications: query suggestions, document classification, many-customer facing tasks, users and customers\n",
    "\n",
    "\n",
    "\n",
    "# Low Precision - High Recall: lower true positive classifications predicted as negative(false negative),\n",
    "# lower true postive classifications of total positive predictions\n",
    "# wide decision boundary\n",
    "# applications: tumor detection, legal applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0b95edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Precision: 0.79\n",
      "Recall: 0.60\n",
      "F1: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)  Also known as sensitivity, or True Positive Rate\n",
    "# F1 = 2 * Precision * Recall / (Precision + Recall) \n",
    "\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, tree_predicted)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test, tree_predicted)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test, tree_predicted)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test, tree_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fb31b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       not 1       0.96      0.98      0.97       407\n",
      "           1       0.79      0.60      0.68        43\n",
      "\n",
      "    accuracy                           0.95       450\n",
      "   macro avg       0.87      0.79      0.83       450\n",
      "weighted avg       0.94      0.95      0.94       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined report with all above metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, tree_predicted, target_names=['not 1', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17532aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random class-proportional (dummy)\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       not 1       0.91      0.89      0.90       407\n",
      "           1       0.12      0.14      0.13        43\n",
      "\n",
      "    accuracy                           0.82       450\n",
      "   macro avg       0.51      0.51      0.51       450\n",
      "weighted avg       0.83      0.82      0.82       450\n",
      "\n",
      "SVM\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       not 1       0.99      0.99      0.99       407\n",
      "           1       0.88      0.88      0.88        43\n",
      "\n",
      "    accuracy                           0.98       450\n",
      "   macro avg       0.94      0.94      0.94       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n",
      "Logistic regression\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       not 1       0.98      0.99      0.98       407\n",
      "           1       0.85      0.81      0.83        43\n",
      "\n",
      "    accuracy                           0.97       450\n",
      "   macro avg       0.92      0.90      0.91       450\n",
      "weighted avg       0.97      0.97      0.97       450\n",
      "\n",
      "Decision tree\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       not 1       0.96      0.98      0.97       407\n",
      "           1       0.79      0.60      0.68        43\n",
      "\n",
      "    accuracy                           0.95       450\n",
      "   macro avg       0.87      0.79      0.83       450\n",
      "weighted avg       0.94      0.95      0.94       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DummyClassifier(null comparison), get evaluation metrics to compare\n",
    "\n",
    "print('Random class-proportional (dummy)\\n', \n",
    "      classification_report(y_test, y_classprop_predicted, target_names=['not 1', '1']))\n",
    "print('SVM\\n', \n",
    "      classification_report(y_test, svm_predicted, target_names = ['not 1', '1']))\n",
    "print('Logistic regression\\n', \n",
    "      classification_report(y_test, lr_predicted, target_names = ['not 1', '1']))\n",
    "print('Decision tree\\n', \n",
    "      classification_report(y_test, tree_predicted, target_names = ['not 1', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9728562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3:  Decision Functions (of probability)\n",
    "# y_scores = model.fit(X_train, y_train).decision_function(X_test)\n",
    "# y_proba = model.fit(X_train, y_train).predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deea4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide info of uncertainty to a prediction, \n",
    "# decision_function or predict_proba\n",
    "\n",
    "# decision_function: provides a classifier's score value, \n",
    "# how confidently classifier predicts.\n",
    "\n",
    "# the positive class(large magnitude positive values),  entre más positivo, más probable que sea class I\n",
    "# the negative class: large magnitude negative values,  entre más negativo, más probable que sea class II\n",
    "\n",
    "\n",
    "# predict_proba: provides predicted probability of class membership\n",
    "# binary classifier, is class with probability greater than 0.5\n",
    "# default threshold> 0.50\n",
    "# higher threshold(more conservative/confident classifier) increases precision, less errors in prediction\n",
    "\n",
    "\n",
    "# chossing a decision threshold gives a classification rule\n",
    "# sweeping decision threshold through range of possible score value,\n",
    "# get a series of classification outcomes that generate the decision functions\n",
    "\n",
    "\n",
    "# precision-recall curve: relación de evaluation metrics de modelos precision-recall curve \n",
    "# a variaciones de threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f3c9e60",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y_binary_imbalanced, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# create LogisticRegression model, parameters: default\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# get model score values with X_test\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m y_scores_lr \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#y_score_list = list(zip(y_test[0:20], y_scores_lr[0:20]))\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# show the decision_function scores for first 20 instances\u001b[39;00m\n\u001b[0;32m     16\u001b[0m y_score_list\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "# load source data \n",
    "dataset = load_digits()\n",
    "\n",
    "# divide source data in X data and y target \n",
    "X, y = dataset.data, dataset.target\n",
    "# divide source data into train-set and test-set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
    "\n",
    "# create LogisticRegression model, parameters: default\n",
    "# get model score values with X_test\n",
    "y_scores_lr = LinearRegression.fit(X_train, y_train)\n",
    "\n",
    "#y_score_list = list(zip(y_test[0:20], y_scores_lr[0:20]))\n",
    "\n",
    "# show the decision_function scores for first 20 instances\n",
    "y_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbedcd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.11050346e-13],\n",
       "       [9.99999996e-01, 3.82022220e-09],\n",
       "       [1.00000000e+00, 2.08621900e-13],\n",
       "       [1.00000000e+00, 3.59565900e-10],\n",
       "       [1.00000000e+00, 1.46732887e-10],\n",
       "       [9.99992541e-01, 7.45923532e-06],\n",
       "       [1.50715898e-03, 9.98492841e-01],\n",
       "       [1.00000000e+00, 7.19868273e-11],\n",
       "       [1.00000000e+00, 1.09172098e-12],\n",
       "       [1.00000000e+00, 2.10180784e-12],\n",
       "       [1.00000000e+00, 1.45299315e-14],\n",
       "       [1.00000000e+00, 1.71548681e-10],\n",
       "       [1.00000000e+00, 1.01050539e-11],\n",
       "       [9.99998461e-01, 1.53867898e-06],\n",
       "       [9.99998716e-01, 1.28391853e-06],\n",
       "       [9.99998340e-01, 1.66043709e-06],\n",
       "       [5.12842655e-06, 9.99994872e-01],\n",
       "       [1.00000000e+00, 1.19274177e-15],\n",
       "       [9.99998207e-01, 1.79324010e-06],\n",
       "       [1.00000000e+00, 1.40451715e-13],\n",
       "       [1.00000000e+00, 3.05032183e-11],\n",
       "       [9.99999849e-01, 1.50922547e-07],\n",
       "       [1.00000000e+00, 6.76047110e-14],\n",
       "       [9.99958766e-01, 4.12341603e-05],\n",
       "       [1.00000000e+00, 1.03201185e-17],\n",
       "       [9.99999998e-01, 1.77297577e-09],\n",
       "       [9.99999998e-01, 2.35850518e-09],\n",
       "       [1.00000000e+00, 1.07368191e-19],\n",
       "       [1.00000000e+00, 1.18305437e-17],\n",
       "       [1.00000000e+00, 8.92849876e-15],\n",
       "       [9.99999999e-01, 9.35476419e-10],\n",
       "       [1.00000000e+00, 2.54373098e-13],\n",
       "       [9.99999244e-01, 7.56196592e-07],\n",
       "       [9.95542971e-01, 4.45702929e-03],\n",
       "       [9.99999920e-01, 7.98306898e-08],\n",
       "       [1.00000000e+00, 1.47068778e-11],\n",
       "       [1.00000000e+00, 1.09708511e-12],\n",
       "       [9.43929611e-01, 5.60703891e-02],\n",
       "       [1.00000000e+00, 3.16955343e-10],\n",
       "       [1.97892815e-08, 9.99999980e-01],\n",
       "       [9.99866011e-01, 1.33989345e-04],\n",
       "       [9.99997762e-01, 2.23840596e-06],\n",
       "       [1.00000000e+00, 2.82218766e-15],\n",
       "       [1.00000000e+00, 1.55478535e-15],\n",
       "       [5.77808544e-01, 4.22191456e-01],\n",
       "       [1.00000000e+00, 1.26720949e-15],\n",
       "       [1.00000000e+00, 1.55252133e-13],\n",
       "       [1.00000000e+00, 6.80354168e-11],\n",
       "       [1.00000000e+00, 1.29345658e-11],\n",
       "       [3.44153985e-03, 9.96558460e-01],\n",
       "       [1.00000000e+00, 6.31728676e-15],\n",
       "       [9.99962823e-01, 3.71772612e-05],\n",
       "       [1.00000000e+00, 1.50961169e-13],\n",
       "       [1.00000000e+00, 3.64808879e-13],\n",
       "       [1.00000000e+00, 2.48025202e-16],\n",
       "       [1.00000000e+00, 7.68408317e-16],\n",
       "       [9.99942896e-01, 5.71040631e-05],\n",
       "       [9.24194293e-01, 7.58057071e-02],\n",
       "       [1.00000000e+00, 4.71049062e-14],\n",
       "       [1.00000000e+00, 2.16437092e-15],\n",
       "       [9.99999889e-01, 1.11455196e-07],\n",
       "       [9.99820073e-01, 1.79927159e-04],\n",
       "       [9.99957623e-01, 4.23765800e-05],\n",
       "       [9.99999998e-01, 2.12954363e-09],\n",
       "       [3.30171992e-03, 9.96698280e-01],\n",
       "       [1.00000000e+00, 1.49078881e-15],\n",
       "       [9.99999435e-01, 5.64703445e-07],\n",
       "       [9.99941709e-01, 5.82905015e-05],\n",
       "       [9.99999552e-01, 4.47626721e-07],\n",
       "       [1.46052198e-02, 9.85394780e-01],\n",
       "       [9.93319780e-01, 6.68021974e-03],\n",
       "       [9.99999998e-01, 2.25291539e-09],\n",
       "       [1.00000000e+00, 1.38368615e-17],\n",
       "       [6.78982315e-09, 9.99999993e-01],\n",
       "       [1.00000000e+00, 4.18576009e-14],\n",
       "       [8.16283392e-01, 1.83716608e-01],\n",
       "       [1.00000000e+00, 3.92396279e-13],\n",
       "       [9.99997468e-01, 2.53187937e-06],\n",
       "       [1.00000000e+00, 1.67664779e-16],\n",
       "       [1.00000000e+00, 6.17981155e-15],\n",
       "       [1.51175417e-05, 9.99984882e-01],\n",
       "       [1.00000000e+00, 1.39222367e-14],\n",
       "       [9.99992203e-01, 7.79692725e-06],\n",
       "       [1.00000000e+00, 1.38404182e-18],\n",
       "       [1.00000000e+00, 6.58840566e-11],\n",
       "       [9.99999999e-01, 1.05412337e-09],\n",
       "       [9.99998244e-01, 1.75599615e-06],\n",
       "       [1.00000000e+00, 1.76872078e-16],\n",
       "       [1.25209938e-01, 8.74790062e-01],\n",
       "       [1.00000000e+00, 1.94809846e-16],\n",
       "       [9.99999977e-01, 2.30009815e-08],\n",
       "       [1.00000000e+00, 1.99309707e-11],\n",
       "       [1.00000000e+00, 1.75547192e-10],\n",
       "       [2.21439226e-05, 9.99977856e-01],\n",
       "       [9.62230102e-02, 9.03776990e-01],\n",
       "       [9.99999238e-01, 7.61576675e-07],\n",
       "       [9.99998649e-01, 1.35068571e-06],\n",
       "       [9.99999694e-01, 3.06151559e-07],\n",
       "       [9.99991282e-01, 8.71841290e-06],\n",
       "       [9.99870773e-01, 1.29226834e-04],\n",
       "       [1.00000000e+00, 1.53643050e-18],\n",
       "       [1.00000000e+00, 3.66305576e-12],\n",
       "       [9.99999991e-01, 8.55972574e-09],\n",
       "       [1.00000000e+00, 2.73314082e-11],\n",
       "       [1.00000000e+00, 4.15009698e-12],\n",
       "       [1.00000000e+00, 7.62112862e-14],\n",
       "       [9.99999999e-01, 7.95965266e-10],\n",
       "       [6.48044896e-05, 9.99935196e-01],\n",
       "       [1.00000000e+00, 6.46240719e-16],\n",
       "       [3.67161298e-01, 6.32838702e-01],\n",
       "       [9.99985611e-01, 1.43886562e-05],\n",
       "       [1.00000000e+00, 5.45303613e-13],\n",
       "       [9.99999998e-01, 1.67323887e-09],\n",
       "       [1.00000000e+00, 1.59536814e-14],\n",
       "       [9.99999772e-01, 2.27532567e-07],\n",
       "       [9.99999845e-01, 1.55042152e-07],\n",
       "       [1.00000000e+00, 1.26259295e-13],\n",
       "       [1.00000000e+00, 3.44775931e-15],\n",
       "       [9.93790831e-01, 6.20916943e-03],\n",
       "       [9.99929738e-01, 7.02622297e-05],\n",
       "       [1.00000000e+00, 6.15779614e-17],\n",
       "       [9.99992405e-01, 7.59485350e-06],\n",
       "       [9.99998654e-01, 1.34569309e-06],\n",
       "       [9.99999991e-01, 9.07063727e-09],\n",
       "       [7.69041260e-01, 2.30958740e-01],\n",
       "       [1.00000000e+00, 1.06145346e-11],\n",
       "       [1.00000000e+00, 3.66845581e-16],\n",
       "       [9.99999997e-01, 2.56698259e-09],\n",
       "       [3.69630532e-01, 6.30369468e-01],\n",
       "       [9.99999989e-01, 1.08926050e-08],\n",
       "       [9.99999878e-01, 1.21915188e-07],\n",
       "       [9.91941629e-01, 8.05837054e-03],\n",
       "       [9.99996168e-01, 3.83166466e-06],\n",
       "       [9.99999999e-01, 1.36416609e-09],\n",
       "       [9.99999995e-01, 4.80829703e-09],\n",
       "       [1.00000000e+00, 3.17805769e-15],\n",
       "       [9.99999999e-01, 7.56411477e-10],\n",
       "       [1.00000000e+00, 3.85516076e-12],\n",
       "       [9.98231650e-01, 1.76834999e-03],\n",
       "       [9.99999958e-01, 4.24630313e-08],\n",
       "       [9.97251652e-01, 2.74834810e-03],\n",
       "       [1.00000000e+00, 4.97973773e-10],\n",
       "       [9.99999885e-01, 1.14639171e-07],\n",
       "       [1.00000000e+00, 1.75708498e-10],\n",
       "       [1.00000000e+00, 8.55229238e-13],\n",
       "       [1.09695157e-07, 9.99999890e-01],\n",
       "       [1.00000000e+00, 6.62955065e-16],\n",
       "       [2.11246391e-02, 9.78875361e-01],\n",
       "       [9.99120211e-01, 8.79789000e-04],\n",
       "       [1.00000000e+00, 8.28685475e-15],\n",
       "       [1.00000000e+00, 2.01168176e-12],\n",
       "       [2.15428161e-02, 9.78457184e-01],\n",
       "       [9.99999999e-01, 1.34710767e-09],\n",
       "       [1.00000000e+00, 2.17868950e-17],\n",
       "       [1.00000000e+00, 3.14377341e-10],\n",
       "       [1.19260345e-01, 8.80739655e-01],\n",
       "       [1.00000000e+00, 1.36422669e-10],\n",
       "       [9.99985672e-01, 1.43280640e-05],\n",
       "       [9.99865326e-01, 1.34674460e-04],\n",
       "       [1.00000000e+00, 1.59613273e-10],\n",
       "       [9.99999766e-01, 2.34216540e-07],\n",
       "       [9.99958631e-01, 4.13689022e-05],\n",
       "       [1.00000000e+00, 1.39997865e-11],\n",
       "       [1.00000000e+00, 1.40857524e-14],\n",
       "       [9.99999547e-01, 4.53308645e-07],\n",
       "       [1.00000000e+00, 4.80475200e-13],\n",
       "       [7.57042172e-01, 2.42957828e-01],\n",
       "       [9.99941099e-01, 5.89011987e-05],\n",
       "       [9.99999924e-01, 7.62483768e-08],\n",
       "       [9.99999836e-01, 1.63799307e-07],\n",
       "       [9.99998848e-01, 1.15170352e-06],\n",
       "       [3.40928379e-04, 9.99659072e-01],\n",
       "       [1.00000000e+00, 1.38999081e-12],\n",
       "       [9.99999963e-01, 3.70102253e-08],\n",
       "       [7.70886207e-04, 9.99229114e-01],\n",
       "       [9.99999998e-01, 2.26238731e-09],\n",
       "       [1.00000000e+00, 2.87688443e-17],\n",
       "       [1.00000000e+00, 4.38279172e-10],\n",
       "       [1.00000000e+00, 1.06041760e-13],\n",
       "       [1.00000000e+00, 4.27439097e-14],\n",
       "       [9.99999999e-01, 9.05495000e-10],\n",
       "       [9.37408887e-01, 6.25911134e-02],\n",
       "       [1.00000000e+00, 1.01067018e-12],\n",
       "       [1.00000000e+00, 6.74400138e-18],\n",
       "       [1.00000000e+00, 2.25825388e-21],\n",
       "       [1.00000000e+00, 2.35375713e-11],\n",
       "       [1.00000000e+00, 9.05360957e-14],\n",
       "       [1.00000000e+00, 3.96755680e-20],\n",
       "       [9.99999998e-01, 2.03072356e-09],\n",
       "       [1.00000000e+00, 6.08595119e-14],\n",
       "       [1.00000000e+00, 2.05481673e-13],\n",
       "       [9.99999936e-01, 6.38906778e-08],\n",
       "       [1.00000000e+00, 6.79800131e-13],\n",
       "       [9.99999980e-01, 2.01499291e-08],\n",
       "       [1.00000000e+00, 1.53973560e-19],\n",
       "       [1.00000000e+00, 9.97544468e-11],\n",
       "       [1.41482124e-04, 9.99858518e-01],\n",
       "       [1.00000000e+00, 1.28926899e-19],\n",
       "       [1.00000000e+00, 1.79312238e-12],\n",
       "       [1.00000000e+00, 8.11928979e-14],\n",
       "       [9.99519831e-01, 4.80169447e-04],\n",
       "       [1.00000000e+00, 1.23461183e-15],\n",
       "       [3.35524800e-04, 9.99664475e-01],\n",
       "       [9.99999996e-01, 3.62922146e-09],\n",
       "       [9.99951825e-01, 4.81750752e-05],\n",
       "       [9.96114023e-01, 3.88597749e-03],\n",
       "       [1.00000000e+00, 1.78870996e-14],\n",
       "       [1.00000000e+00, 2.79386943e-12],\n",
       "       [1.00000000e+00, 5.60940501e-15],\n",
       "       [1.00000000e+00, 3.34395910e-13],\n",
       "       [1.00000000e+00, 3.70930605e-13],\n",
       "       [9.95192505e-01, 4.80749455e-03],\n",
       "       [9.99999945e-01, 5.52642338e-08],\n",
       "       [9.28453497e-01, 7.15465030e-02],\n",
       "       [1.00000000e+00, 4.24158092e-12],\n",
       "       [9.99995558e-01, 4.44201818e-06],\n",
       "       [2.22753391e-06, 9.99997772e-01],\n",
       "       [9.03454987e-01, 9.65450128e-02],\n",
       "       [9.99566086e-01, 4.33913659e-04],\n",
       "       [1.00000000e+00, 3.65709722e-17],\n",
       "       [1.00000000e+00, 8.44718275e-12],\n",
       "       [9.99999972e-01, 2.78865276e-08],\n",
       "       [9.99999473e-01, 5.26574925e-07],\n",
       "       [9.99999999e-01, 9.68426947e-10],\n",
       "       [9.98102489e-01, 1.89751124e-03],\n",
       "       [9.99999999e-01, 6.34190108e-10],\n",
       "       [9.99928695e-01, 7.13045163e-05],\n",
       "       [1.00000000e+00, 4.39194325e-14],\n",
       "       [9.99999908e-01, 9.20139097e-08],\n",
       "       [7.50947041e-03, 9.92490530e-01],\n",
       "       [9.99999990e-01, 1.03892874e-08],\n",
       "       [1.00000000e+00, 2.05938344e-18],\n",
       "       [1.00000000e+00, 8.91527642e-23],\n",
       "       [1.00000000e+00, 4.05110263e-17],\n",
       "       [1.00000000e+00, 3.21700591e-11],\n",
       "       [1.00000000e+00, 3.17294776e-14],\n",
       "       [9.99999999e-01, 1.13424587e-09],\n",
       "       [1.00000000e+00, 3.34147227e-17],\n",
       "       [1.00000000e+00, 4.77349512e-20],\n",
       "       [1.00000000e+00, 1.56040337e-10],\n",
       "       [1.91197428e-03, 9.98088026e-01],\n",
       "       [3.47257932e-04, 9.99652742e-01],\n",
       "       [9.99999998e-01, 1.60916197e-09],\n",
       "       [1.00000000e+00, 8.88272938e-12],\n",
       "       [9.99999819e-01, 1.80947145e-07],\n",
       "       [9.99999489e-01, 5.11339950e-07],\n",
       "       [9.31736927e-01, 6.82630733e-02],\n",
       "       [9.99999999e-01, 1.21860651e-09],\n",
       "       [1.00000000e+00, 8.03099209e-13],\n",
       "       [9.99999238e-01, 7.62464550e-07],\n",
       "       [9.99997479e-01, 2.52066117e-06],\n",
       "       [1.00000000e+00, 2.63667097e-21],\n",
       "       [9.99999829e-01, 1.71079075e-07],\n",
       "       [1.00000000e+00, 3.09007053e-12],\n",
       "       [9.99999915e-01, 8.53304288e-08],\n",
       "       [1.00000000e+00, 8.15727409e-14],\n",
       "       [9.99999940e-01, 6.00955853e-08],\n",
       "       [9.99999961e-01, 3.90104161e-08],\n",
       "       [1.00000000e+00, 9.97670951e-12],\n",
       "       [1.00000000e+00, 1.73804670e-11],\n",
       "       [9.99999771e-01, 2.29439650e-07],\n",
       "       [3.97668755e-01, 6.02331245e-01],\n",
       "       [9.99997694e-01, 2.30568644e-06],\n",
       "       [5.56005339e-02, 9.44399466e-01],\n",
       "       [1.00000000e+00, 4.50048145e-15],\n",
       "       [1.00000000e+00, 1.77365927e-10],\n",
       "       [9.99999112e-01, 8.87515311e-07],\n",
       "       [9.99882136e-01, 1.17863619e-04],\n",
       "       [9.99982945e-01, 1.70552096e-05],\n",
       "       [1.00000000e+00, 1.19787423e-14],\n",
       "       [1.00000000e+00, 1.41269056e-10],\n",
       "       [9.99999998e-01, 1.52838729e-09],\n",
       "       [9.99999997e-01, 3.20459887e-09],\n",
       "       [9.99998766e-01, 1.23372351e-06],\n",
       "       [1.00000000e+00, 5.43080565e-22],\n",
       "       [9.86805493e-01, 1.31945068e-02],\n",
       "       [9.99999998e-01, 1.57297384e-09],\n",
       "       [9.95575637e-01, 4.42436303e-03],\n",
       "       [9.99957440e-01, 4.25600880e-05],\n",
       "       [1.00000000e+00, 2.24179930e-14],\n",
       "       [1.00000000e+00, 2.90249603e-12],\n",
       "       [9.99999999e-01, 1.30112240e-09],\n",
       "       [1.00000000e+00, 1.32405430e-10],\n",
       "       [9.99999773e-01, 2.26705643e-07],\n",
       "       [9.99999997e-01, 2.59697499e-09],\n",
       "       [9.82116806e-01, 1.78831936e-02],\n",
       "       [1.00000000e+00, 3.88611500e-11],\n",
       "       [1.00000000e+00, 5.50675415e-13],\n",
       "       [1.00000000e+00, 1.03211079e-11],\n",
       "       [9.99999995e-01, 4.63555885e-09],\n",
       "       [1.00000000e+00, 1.43958194e-10],\n",
       "       [1.00000000e+00, 1.71085330e-12],\n",
       "       [9.99999963e-01, 3.67888927e-08],\n",
       "       [1.00000000e+00, 3.23295755e-18],\n",
       "       [1.00000000e+00, 2.32268146e-15],\n",
       "       [9.99908254e-01, 9.17457658e-05],\n",
       "       [1.00000000e+00, 9.05796973e-12],\n",
       "       [9.99999790e-01, 2.10050092e-07],\n",
       "       [9.99999402e-01, 5.98140810e-07],\n",
       "       [9.99999876e-01, 1.24034168e-07],\n",
       "       [1.00000000e+00, 9.56310745e-18],\n",
       "       [9.73154947e-01, 2.68450528e-02],\n",
       "       [9.99999913e-01, 8.70858275e-08],\n",
       "       [1.00000000e+00, 2.83865783e-11],\n",
       "       [1.00000000e+00, 1.99475170e-13],\n",
       "       [9.99999276e-01, 7.23993148e-07],\n",
       "       [1.00000000e+00, 2.18863350e-11],\n",
       "       [1.00000000e+00, 6.24218667e-17],\n",
       "       [1.00000000e+00, 2.89558947e-13],\n",
       "       [9.99990763e-01, 9.23737848e-06],\n",
       "       [1.00000000e+00, 3.45903178e-18],\n",
       "       [9.99999929e-01, 7.05556117e-08],\n",
       "       [9.99999988e-01, 1.16906647e-08],\n",
       "       [1.00000000e+00, 9.23898296e-12],\n",
       "       [1.00000000e+00, 2.71975963e-10],\n",
       "       [9.99999928e-01, 7.21627446e-08],\n",
       "       [1.00000000e+00, 4.39713335e-13],\n",
       "       [9.99999969e-01, 3.12466819e-08],\n",
       "       [1.00000000e+00, 1.14280700e-15],\n",
       "       [9.99999975e-01, 2.46911350e-08],\n",
       "       [9.99999956e-01, 4.44904683e-08],\n",
       "       [1.00000000e+00, 3.41717828e-15],\n",
       "       [1.00000000e+00, 7.70177205e-12],\n",
       "       [1.00000000e+00, 2.26306955e-10],\n",
       "       [9.99840104e-01, 1.59895867e-04],\n",
       "       [5.40495101e-01, 4.59504899e-01],\n",
       "       [9.99998136e-01, 1.86420555e-06],\n",
       "       [3.73842112e-06, 9.99996262e-01],\n",
       "       [1.00000000e+00, 7.61160244e-17],\n",
       "       [9.99976241e-01, 2.37590494e-05],\n",
       "       [1.00000000e+00, 2.03913121e-10],\n",
       "       [9.94458235e-01, 5.54176491e-03],\n",
       "       [1.00000000e+00, 1.10054788e-10],\n",
       "       [9.99999998e-01, 1.86218012e-09],\n",
       "       [1.00000000e+00, 2.10700607e-14],\n",
       "       [9.99998910e-01, 1.09013214e-06],\n",
       "       [9.99999913e-01, 8.70095289e-08],\n",
       "       [1.00000000e+00, 1.64195499e-12],\n",
       "       [1.00000000e+00, 3.68719623e-14],\n",
       "       [9.54755742e-04, 9.99045244e-01],\n",
       "       [8.91844559e-01, 1.08155441e-01],\n",
       "       [3.48238636e-06, 9.99996518e-01],\n",
       "       [1.00000000e+00, 1.93738192e-10],\n",
       "       [9.99794653e-01, 2.05346898e-04],\n",
       "       [9.82017248e-01, 1.79827517e-02],\n",
       "       [1.00000000e+00, 1.67214562e-12],\n",
       "       [1.00000000e+00, 3.69769956e-12],\n",
       "       [9.99999990e-01, 1.01556980e-08],\n",
       "       [4.84725941e-02, 9.51527406e-01],\n",
       "       [4.05458230e-02, 9.59454177e-01],\n",
       "       [1.00000000e+00, 8.34925035e-12],\n",
       "       [1.00000000e+00, 5.18731406e-14],\n",
       "       [9.99999995e-01, 5.36058383e-09],\n",
       "       [1.00000000e+00, 1.74600969e-16],\n",
       "       [1.00000000e+00, 2.54075708e-10],\n",
       "       [1.00000000e+00, 3.07263899e-13],\n",
       "       [1.00000000e+00, 4.91733808e-14],\n",
       "       [9.99999999e-01, 1.11384793e-09],\n",
       "       [9.94774164e-01, 5.22583591e-03],\n",
       "       [9.99999992e-01, 7.90107865e-09],\n",
       "       [1.00000000e+00, 1.55093367e-12],\n",
       "       [1.00000000e+00, 1.85097367e-10],\n",
       "       [1.00000000e+00, 1.05822837e-17],\n",
       "       [9.99999956e-01, 4.39962376e-08],\n",
       "       [1.00000000e+00, 1.08653415e-12],\n",
       "       [9.99982162e-01, 1.78377791e-05],\n",
       "       [1.00000000e+00, 3.65446816e-14],\n",
       "       [9.99999216e-01, 7.83552626e-07],\n",
       "       [1.00000000e+00, 1.30849313e-11],\n",
       "       [1.00000000e+00, 2.91758825e-14],\n",
       "       [9.99999990e-01, 9.60355548e-09],\n",
       "       [1.00000000e+00, 6.39693756e-11],\n",
       "       [1.00000000e+00, 1.99339126e-15],\n",
       "       [1.00000000e+00, 7.18874814e-15],\n",
       "       [9.99999920e-01, 7.99126671e-08],\n",
       "       [9.99999934e-01, 6.59593174e-08],\n",
       "       [1.00000000e+00, 2.10727489e-14],\n",
       "       [1.00000000e+00, 2.49835929e-13],\n",
       "       [1.00000000e+00, 2.80235897e-17],\n",
       "       [9.99998488e-01, 1.51237617e-06],\n",
       "       [7.53463923e-02, 9.24653608e-01],\n",
       "       [9.99902277e-01, 9.77227430e-05],\n",
       "       [9.99999670e-01, 3.30219294e-07],\n",
       "       [1.00000000e+00, 5.00759899e-15],\n",
       "       [1.00000000e+00, 1.10210780e-14],\n",
       "       [9.99950638e-01, 4.93618128e-05],\n",
       "       [1.00000000e+00, 6.32317863e-11],\n",
       "       [1.00000000e+00, 2.81584195e-15],\n",
       "       [9.99997533e-01, 2.46746103e-06],\n",
       "       [1.00000000e+00, 2.47536856e-12],\n",
       "       [1.00000000e+00, 1.02356172e-15],\n",
       "       [9.99992549e-01, 7.45070886e-06],\n",
       "       [1.00000000e+00, 6.18833074e-15],\n",
       "       [1.00000000e+00, 3.90047104e-11],\n",
       "       [9.99999997e-01, 3.29604408e-09],\n",
       "       [9.99998833e-01, 1.16665158e-06],\n",
       "       [1.00000000e+00, 1.36977316e-19],\n",
       "       [1.00000000e+00, 1.66175798e-10],\n",
       "       [8.98743691e-04, 9.99101256e-01],\n",
       "       [1.00000000e+00, 1.66687348e-12],\n",
       "       [9.23549629e-01, 7.64503708e-02],\n",
       "       [9.99999998e-01, 2.19488193e-09],\n",
       "       [1.00000000e+00, 5.45687441e-14],\n",
       "       [1.00000000e+00, 1.25221594e-11],\n",
       "       [9.99999943e-01, 5.69449968e-08],\n",
       "       [9.99844388e-01, 1.55611687e-04],\n",
       "       [1.00000000e+00, 7.00205617e-14],\n",
       "       [9.99833047e-01, 1.66952518e-04],\n",
       "       [1.76690937e-02, 9.82330906e-01],\n",
       "       [1.00000000e+00, 1.09090827e-13],\n",
       "       [1.00000000e+00, 2.74402533e-20],\n",
       "       [9.99998565e-01, 1.43512064e-06],\n",
       "       [1.00000000e+00, 1.14880368e-15],\n",
       "       [9.99999870e-01, 1.29582564e-07],\n",
       "       [1.00000000e+00, 3.89758175e-14],\n",
       "       [9.99592903e-01, 4.07097158e-04],\n",
       "       [2.69269428e-01, 7.30730572e-01],\n",
       "       [9.99999792e-01, 2.07974523e-07],\n",
       "       [9.99999960e-01, 3.98737321e-08],\n",
       "       [1.00000000e+00, 8.22463400e-19],\n",
       "       [4.97351486e-03, 9.95026485e-01],\n",
       "       [1.00000000e+00, 7.68863756e-14],\n",
       "       [9.99999999e-01, 1.25743100e-09],\n",
       "       [7.65204351e-01, 2.34795649e-01],\n",
       "       [1.00000000e+00, 9.85010423e-13],\n",
       "       [9.99999994e-01, 6.10459557e-09],\n",
       "       [1.00000000e+00, 1.02854135e-14],\n",
       "       [1.00000000e+00, 1.07674100e-13],\n",
       "       [1.00000000e+00, 5.96694058e-13],\n",
       "       [1.00000000e+00, 6.18911164e-21],\n",
       "       [1.00000000e+00, 3.45555013e-12],\n",
       "       [1.00000000e+00, 1.25105865e-24],\n",
       "       [1.00000000e+00, 1.56981724e-11],\n",
       "       [9.99999901e-01, 9.88605612e-08],\n",
       "       [1.58693276e-05, 9.99984131e-01],\n",
       "       [1.00000000e+00, 7.34300925e-11],\n",
       "       [1.00000000e+00, 5.62610654e-13],\n",
       "       [9.98345407e-01, 1.65459331e-03],\n",
       "       [1.00000000e+00, 2.00185185e-15],\n",
       "       [9.99999995e-01, 5.17764836e-09],\n",
       "       [9.99999999e-01, 1.11232349e-09],\n",
       "       [5.92951105e-01, 4.07048895e-01],\n",
       "       [1.00000000e+00, 7.45555770e-11],\n",
       "       [9.99570218e-01, 4.29782418e-04],\n",
       "       [8.48453472e-04, 9.99151547e-01],\n",
       "       [1.00000000e+00, 2.22842410e-11],\n",
       "       [9.99999989e-01, 1.09881997e-08],\n",
       "       [9.99999405e-01, 5.94856001e-07],\n",
       "       [1.70202442e-05, 9.99982980e-01],\n",
       "       [1.00000000e+00, 2.21823811e-19]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load source data \n",
    "dataset = load_digits()\n",
    "\n",
    "# divide source data in X data and y target \n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "# divide source data into train-set and test-set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
    "\n",
    "# create LogisticRegression model, parameters: default.\n",
    "# predict_proba(X_test) predict probability of X_test\n",
    "y_proba_lr = lr.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_proba_list = list(zip(y_test[0:20], y_proba_lr[0:20,1]))\n",
    "\n",
    "# show the probability of positive class for first 20 instances\n",
    "y_proba_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall curves and ROC curves\n",
    "# precision, recall, thresholds = precision_recall_curve(y_test, y_scores_model) \n",
    "# fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall curve: Evaluation metrics curves and trade-offs\n",
    "# ideal classifier: precision=recall=1\n",
    "# entre más cerca el punto de threshold a top right, mejor\n",
    "# steep of P-R curve: maximize precision while maximize recall\n",
    "\n",
    "\n",
    "# ROC curve: reciving operating characteristic curves for binary classification\n",
    "# x-False Positive Rate vs y-True Positive Rate\n",
    "# ideal ROC point is top left X-False Positive Rate=0, y-True Positive=1\n",
    "# steep of ROC curve: maximize true positive rate, while minimize the false positive rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4313690",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_scores_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_recall_curve\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# precision_recall_curve(y_test, y_scores_lr),\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# create precision-recall curve,  parameters: y_test, y_model score values\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m precision, recall, thresholds \u001b[38;5;241m=\u001b[39m precision_recall_curve(y_test, \u001b[43my_scores_lr\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# get min(abs(threshold)) threshold minimo \u001b[39;00m\n\u001b[0;32m      8\u001b[0m closest_zero \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(np\u001b[38;5;241m.\u001b[39mabs(thresholds))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_scores_lr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# precision_recall_curve(y_test, y_scores_lr),\n",
    "# create precision-recall curve,  parameters: y_test, y_model score values\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores_lr)\n",
    "\n",
    "# get min(abs(threshold)) threshold minimo \n",
    "closest_zero = np.argmin(np.abs(thresholds))\n",
    "# get min precision value at min threshold\n",
    "closest_zero_p = precision[closest_zero]\n",
    "# get min recall value at min thresholds\n",
    "closest_zero_r = recall[closest_zero]\n",
    "\n",
    "# plot\n",
    "plt.figure()\n",
    "plt.xlim([0.0, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.plot(precision, recall, label='Precision-Recall Curve')\n",
    "plt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n",
    "plt.xlabel('Precision', fontsize=16)\n",
    "plt.ylabel('Recall', fontsize=16)\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb899b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# divide source data into train-set and test-set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
    "\n",
    "# get y_model score values from X_test \n",
    "y_score_lr = lr.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# create roc curve,  parameters: y_test, y_model score values\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_lr)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.plot(fpr_lr, tpr_lr, lw=3, label='LogRegr ROC curve (area = {:0.2f})'.format(roc_auc_lr))\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve (1-of-10 digits classifier)', fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "for g in [0.01, 0.1, 0.20, 1]:\n",
    "    svm = SVC(gamma=g).fit(X_train, y_train)\n",
    "    y_score_svm = svm.decision_function(X_test)\n",
    "    fpr_svm, tpr_svm, _ = roc_curve(y_test, y_score_svm)\n",
    "    roc_auc_svm = auc(fpr_svm, tpr_svm)\n",
    "    accuracy_svm = svm.score(X_test, y_test)\n",
    "    print(\"gamma = {:.2f}  accuracy = {:.2f}   AUC = {:.2f}\".format(g, accuracy_svm, \n",
    "                                                                    roc_auc_svm))\n",
    "    plt.plot(fpr_svm, tpr_svm, lw=3, alpha=0.7, \n",
    "             label='SVM (gamma = {:0.2f}, area = {:0.2f})'.format(g, roc_auc_svm))\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
    "plt.plot([0, 1], [0, 1], color='k', lw=0.5, linestyle='--')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.title('ROC curve: (1-of-10 digits classifier)', fontsize=16)\n",
    "plt.axes().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3: Multi-class Evaluation, extension of binary classification\n",
    "# one class vs multiple class\n",
    "\n",
    "# df_cm = pd.DataFrame(confusion_mc, index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "# confusion_mc = confusion_matrix(y_test_mc, svm_predicted_mc)\n",
    "# classification_report(y_test_mc, svm_predicted_mc)\n",
    "\n",
    "# precision_score(y_test_mc, svm_predicted_mc, average = 'micro')\n",
    "# precision_score(y_test_mc, svm_predicted_mc, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General evaluation metrics are averaged across multiple classes\n",
    "# multi-label classification: each instance can have multiple labels\n",
    "\n",
    "# always look at the confussion matrix to see what kind of errors generate\n",
    "\n",
    "# macro avg metric = SUM(metric of each class)\n",
    "# micro avg metric = correct predictions/total prediction\n",
    "\n",
    "# model with classes of about same number of instances, then macro=micro\n",
    "\n",
    "# model with classes much larger than others, then:\n",
    "# 1. for weight metric toward the largest ones, use micro\n",
    "# 2. for weight metric toward the smallest ones, use macro\n",
    "\n",
    "# if micro is much lower than macro, examine large classes for poor metric performance/score\n",
    "# if macro is much lower than micro, examine small classes for poor metric performance/score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5e19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load source data \n",
    "dataset = load_digits()\n",
    "# set X data, y target from source data\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "# divide source data in train-source and test-source\n",
    "X_train_mc, X_test_mc, y_train_mc, y_test_mc = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# create SVectorMachine Linear Kernel, parameters: kernel function = 'linear', fit/train\n",
    "svm = SVC(kernel = 'linear').fit(X_train_mc, y_train_mc)\n",
    "# get y_predicted values for the model \n",
    "svm_predicted_mc = svm.predict(X_test_mc)\n",
    "\n",
    "# get confusion matrix, parameters:y_test_mc, y_predicted_model\n",
    "confusion_mc = confusion_matrix(y_test_mc, svm_predicted_mc)\n",
    "\n",
    "# create DataFrame with confusion matrix\n",
    "df_cm = pd.DataFrame(confusion_mc, \n",
    "                     index = [i for i in range(0,10)], columns = [i for i in range(0,10)])\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test_mc, \n",
    "                                                                       svm_predicted_mc)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# create SVectorMachine RBF Kernel model, parameters: kernel func='RBF', fit/train\n",
    "svm = SVC(kernel = 'rbf').fit(X_train_mc, y_train_mc)\n",
    "\n",
    "# # get y_predicted values for the model with X_test test-set\n",
    "svm_predicted_mc = svm.predict(X_test_mc)\n",
    "# get confusion matrix (evaluation metrics)\n",
    "confusion_mc = confusion_matrix(y_test_mc, svm_predicted_mc)\n",
    "df_cm = pd.DataFrame(confusion_mc, index = [i for i in range(0,10)],\n",
    "                  columns = [i for i in range(0,10)])\n",
    "# plot\n",
    "plt.figure(figsize = (5.5,4))\n",
    "sns.heatmap(df_cm, annot=True)\n",
    "plt.title('SVM RBF Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test_mc, \n",
    "                                                                    svm_predicted_mc)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1bcd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_mc, svm_predicted_mc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f361ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Micro-averaged precision = {:.2f} (treat instances equally)'\n",
    "      .format(precision_score(y_test_mc, svm_predicted_mc, average = 'micro')))\n",
    "print('Macro-averaged precision = {:.2f} (treat classes equally)'\n",
    "      .format(precision_score(y_test_mc, svm_predicted_mc, average = 'macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Micro-averaged f1 = {:.2f} (treat instances equally)'\n",
    "      .format(f1_score(y_test_mc, svm_predicted_mc, average = 'micro')))\n",
    "print('Macro-averaged f1 = {:.2f} (treat classes equally)'\n",
    "      .format(f1_score(y_test_mc, svm_predicted_mc, average = 'macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3: Metricas de evaluacion en Regression \n",
    "\n",
    "# r2_score(y_test, y_predict_model):  R2 ajuste del modelo lineal (mala métrica en el test-set)\n",
    "# mean_squared_error(y_test,y_predict_model)):  MSE métrica optima, el ajuste de los parámetros de OLS es con MSE. La raíz cuadrada de la suma de errores en promedio\n",
    "# mean_absolute_error(y_test,y_predict_model))\n",
    "# median_abs_error(y_test,y_predict_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  trade-off  entre métricas de evaluación \n",
    "# Métricas de evaluación  graficadas en funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c9616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegresiónMétricas de evaluación:\n",
    "\n",
    "\n",
    "# mean_absolute_error = abs(y_target-y_predicted) )\n",
    "# mean_squared_error = (y_target-y_predicted)^2 \n",
    "# median_abs_error = robust to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DummyRegressors implements 4 simple baseline rules for regression\n",
    "# mean: predicts the mean of the train-set y target values\n",
    "# median: predicts the median of the train-set y target values\n",
    "# quantile(porcentil): predicts a user quantile of the train-set y target values (75%)\n",
    "# constant: predicts user constant value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11864abd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# load source data\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# divide source data into X data and y target values\n",
    "X = diabetes.data[:, None, 6]\n",
    "y = diabetes.target\n",
    "\n",
    "# divide data into train-set and test-set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# create LinearRegression() model, parameters: default\n",
    "lm = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# create  DummyRegressor, parameters: mean predicts the mean of the train-set y target values\n",
    "lm_dummy_mean = DummyRegressor(strategy = 'mean').fit(X_train, y_train)\n",
    "\n",
    "# get y predicted values from LinearRegression model\n",
    "y_predict = lm.predict(X_test)\n",
    "\n",
    "# get y predicted values from DummyRegressor mean model\n",
    "y_predict_dummy_mean = lm_dummy_mean.predict(X_test)\n",
    "\n",
    "print('Linear model, coefficients: ', lm.coef_)\n",
    "print(\"Mean squared error (dummy): {:.2f}\".format(mean_squared_error(y_test, \n",
    "                                                                     y_predict_dummy_mean)))\n",
    "\n",
    "print(\"Mean squared error (linear model): {:.2f}\".format(mean_squared_error(y_test, y_predict)))\n",
    "print(\"r2_score (dummy): {:.2f}\".format(r2_score(y_test, y_predict_dummy_mean)))\n",
    "print(\"r2_score (linear model): {:.2f}\".format(r2_score(y_test, y_predict)))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test, y_test,  color='black')\n",
    "plt.plot(X_test, y_predict, color='green', linewidth=2)\n",
    "plt.plot(X_test, y_predict_dummy_mean, color='red', linestyle = 'dashed', \n",
    "         linewidth=2, label = 'dummy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Week 3: Selección de modelo, escoger mejor clasificador \n",
    "# cross_val_score(model, X_data, y_labels, cv=param):  validación cruzada  k-fold\n",
    "# grid_search = GridSearchCV(model, param_grid = param_range, scoring = evaluation_metric ):  ***Clase para encontrar hiper parámetros óptimo \n",
    "# grid_search.fit(X_train, y_train)\n",
    "# y_decision_fn_scores_eval = grid_search.decision_function(X_test):  retorna la función de decisión que son las probabilidades de pertenencia a una clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360bc7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de modelo:\n",
    "# 1. train/test en 1 base: (métrica única, overfit malo, low accuracy may indicate implementation code error)\n",
    "# 2. single train,test split produce únicas métricas de evaluación ( single metric, lack of variance, not good picture of future predictions)\n",
    "# 3. k-fold cross-validations para dividir la base en k-fold, then promediar las métricas evaluación. (más estable)\n",
    "\n",
    "# scoring = 'evaluation_metric' ,  crear  cross-val  para una métrica de evaluación especifica a optimizar \n",
    "# cross_val_score(clf, X, y, cv=5, scoring = eval_metric)\n",
    "# generar  cross-val score para modelo con diferentes métricas de evaluación \n",
    "\n",
    "\n",
    "# GridSearchCV(model, param_grid = parameter_range), encontrar los hiper parámetros óptimos para el modelo fit/train ajustado dada una base\n",
    "# para optimizar una métrica evaluación dada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e05e62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# load source data\n",
    "dataset = load_digits()\n",
    "# again, making this a binary problem with 'digit 1' as positive class \n",
    "# and 'not 1' as negative class\n",
    "X, y = dataset.data, dataset.target == 1\n",
    "\n",
    "# create SVectorMachine Linear, parameters: kernel='linear', C=1\n",
    "clf = SVC(kernel='linear', C=1)\n",
    "\n",
    "# generate cross-val score for model with different evaluation metrics\n",
    "\n",
    "# accuracy is the default scoring metric\n",
    "print('Cross-validation (accuracy)', cross_val_score(clf, X, y, cv=5 )  )\n",
    "print('Average cross-validation, evaluation metric= Accuracy:', np.average(cross_val_score(clf, X, y, cv=5) ))\n",
    "print('\\b')\n",
    "# use AUC as scoring metric\n",
    "print('Cross-validation (AUC)', cross_val_score(clf, X, y, cv=5, scoring = 'roc_auc'))\n",
    "print('Average cross-validation, evaluation metric= AUC:', np.average(cross_val_score(clf, X, y, cv=5, scoring = 'roc_auc') ))\n",
    "print('\\b')\n",
    "# use recall as scoring metric\n",
    "print('Cross-validation (recall)', cross_val_score(clf, X, y, cv=5, scoring = 'recall'))\n",
    "print('Average cross-validation, evaluation metric= recall:', np.average(cross_val_score(clf, X, y, cv=5, scoring = 'recall') ))\n",
    "print('\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# load source data\n",
    "dataset = load_digits()\n",
    "\n",
    "# create unbalanced 0-1 binary class dataset\n",
    "X, y = dataset.data, dataset.target == 1\n",
    "\n",
    "# divide source data into train-set and test-set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# create SVectorMachine RBF, parameters: kernel='rbf'\n",
    "clf = SVC(kernel='rbf')\n",
    "\n",
    "# gamma parameter range to search over\n",
    "grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100]}\n",
    "\n",
    "\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "\n",
    "# GridSearchCV(clf, param_grid = grid_values), \n",
    "#find the value of parameter that optimizes a given evaluation metric   over its range\n",
    "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values, scoring = 'accuracy')\n",
    "grid_clf_acc.fit(X_train, y_train)\n",
    "\n",
    "# optimize model for evaluation metric average accuracy\n",
    "y_decision_fn_scores_acc = grid_clf_acc.decision_function(X_test) \n",
    "\n",
    "print('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\n",
    "print('Grid best score (accuracy): ', grid_clf_acc.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "# alternative metric to optimize over grid parameters: AUC\n",
    "\n",
    "# GridSearchCV(clf, param_grid = grid_values), find the value of parameter\n",
    "# that optimizes a given evaluation metric \n",
    "grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_clf_auc.fit(X_train, y_train)\n",
    "# optimize model for evaluation metric AUC\n",
    "y_decision_fn_scores_auc = grid_clf_auc.decision_function(X_test) \n",
    "\n",
    "\n",
    "print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "\n",
    "\n",
    "# crear SupportVectorMachine optimo\n",
    "svm =  SVC(kernel='rbf',gamma=0.001).fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# crear vector de predicciones y_hat\n",
    "\n",
    "y_hat_train = svm.predict(X_train)\n",
    "y_hat_test = svm.predict(X_test)\n",
    "\n",
    "\n",
    "# matriz de confusion\n",
    "confusion_train = confusion_matrix(y_train, y_hat_train)\n",
    "confusion_test = confusion_matrix(y_test, y_hat_test)\n",
    "\n",
    "# metricas de evaluacion\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_hat_train )\n",
    "test_acc = accuracy_score(y_test, y_hat_test )\n",
    "\n",
    "train_prec =precision_score(y_train, y_hat_train)\n",
    "test_prec =precision_score(y_test, y_hat_test )\n",
    "\n",
    "train_recall = recall_score(y_train, y_hat_train )\n",
    "test_recall = recall_score(y_test, y_hat_test )\n",
    "\n",
    "train_f1 = f1_score(y_train, y_hat_train )\n",
    "test_f1 = f1_score(y_test, y_hat_test )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dadbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.scorer import SCORERS\n",
    "\n",
    "print(sorted(list(SCORERS.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f89fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different evaluation metrics\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load data \n",
    "dataset = load_digits()\n",
    "X, y = dataset.data, dataset.target == 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Create a two-feature input vector matching the example plot above\n",
    "# We jitter the points (add a small amount of random noise) in case there are areas\n",
    "# in feature space where many instances have the same features.\n",
    "\n",
    "# use GridSearh to explore different weigths given during training\n",
    "# \n",
    "\n",
    "\n",
    "jitter_delta = 0.25\n",
    "X_twovar_train = X_train[:,[20,59]]+ np.random.rand(X_train.shape[0], 2) - jitter_delta\n",
    "X_twovar_test  = X_test[:,[20,59]] + np.random.rand(X_test.shape[0], 2) - jitter_delta\n",
    "\n",
    "# create SVector Machine Linear, parameters: kernel = linear, fit/train with train-set\n",
    "clf = SVC(kernel = 'linear').fit(X_twovar_train, y_train)\n",
    "\n",
    "# class weight parameter of weight\n",
    "grid_values = {'class_weight':['balanced', {1:2},{1:3},{1:4},{1:5},{1:10},{1:20},{1:50}]}\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "# iterate over evaluation metrics\n",
    "for i, eval_metric in enumerate(('precision','recall', 'f1','roc_auc')):\n",
    "    \n",
    "    #find the value of parameter that optimizes a given evaluation metric \n",
    "    grid_clf_custom = GridSearchCV(clf, param_grid=grid_values, scoring=eval_metric)\n",
    "    grid_clf_custom.fit(X_twovar_train, y_train)\n",
    "    \n",
    "    # get best parameter for score\n",
    "    print('Grid best parameter (max. {0}): {1}'\n",
    "          .format(eval_metric, grid_clf_custom.best_params_))\n",
    "    # get best score/performance metric\n",
    "    print('Grid best score ({0}): {1}'\n",
    "          .format(eval_metric, grid_clf_custom.best_score_))\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "    plot_class_regions_for_classifier_subplot(grid_clf_custom, X_twovar_test, y_test, None,\n",
    "                                             None, None,  plt.subplot(2, 2, i+1))\n",
    "    \n",
    "    plt.title(eval_metric+'-oriented SVC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f76a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "dataset = load_digits()\n",
    "X, y = dataset.data, dataset.target == 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# create a two-feature input vector matching the example plot above\n",
    "jitter_delta = 0.25\n",
    "X_twovar_train = X_train[:,[20,59]]+ np.random.rand(X_train.shape[0], 2) - jitter_delta\n",
    "X_twovar_test  = X_test[:,[20,59]] + np.random.rand(X_test.shape[0], 2) - jitter_delta\n",
    "\n",
    "clf = SVC(kernel='linear', class_weight='balanced').fit(X_twovar_train, y_train)\n",
    "\n",
    "y_scores = clf.decision_function(X_twovar_test)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "closest_zero = np.argmin(np.abs(thresholds))\n",
    "closest_zero_p = precision[closest_zero]\n",
    "closest_zero_r = recall[closest_zero]\n",
    "\n",
    "plot_class_regions_for_classifier(clf, X_twovar_test, y_test)\n",
    "plt.title(\"SVC, class_weight = 'balanced', optimized for accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim([0.0, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.title (\"Precision-recall curve: SVC, class_weight = 'balanced'\")\n",
    "plt.plot(precision, recall, label = 'Precision-Recall Curve')\n",
    "plt.plot(closest_zero_p, closest_zero_r, 'o', markersize=12, fillstyle='none', c='r', mew=3)\n",
    "plt.xlabel('Precision', fontsize=16)\n",
    "plt.ylabel('Recall', fontsize=16)\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()\n",
    "print('At zero threshold, precision: {:.2f}, recall: {:.2f}'\n",
    "      .format(closest_zero_p, closest_zero_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9175e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
