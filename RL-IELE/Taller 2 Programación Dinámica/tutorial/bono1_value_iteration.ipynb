{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias que contienen la dinámica del entorno gridworld\n",
    "from types import MethodType\n",
    "from gridworld import GridWorld, pygame\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorld(rows=4, cols=4, walls=[], pits=[], goals=[(0,0),(3,3)], live_reward=0.0)\n",
    "gw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMENTAR TODO EL CODIGO\n",
    "\n",
    "# def: método de PD: value iteration para calcular v(s) y política óptima\n",
    "# parametros: gw=MDP GridWorld (Taller 2), gamma=tasa de descuento (0.9)\n",
    "\n",
    "def value_iteration(gw, gamma):\n",
    "    \n",
    "    new_values = dict.fromkeys(gw.states , 0.0) # inicializa vector de valores de estado v0(s)=0 \n",
    "    \n",
    "    r_trans = -1 # recompensa de transicion\n",
    "    \n",
    "    # iterar sobre estados\n",
    "    for state in gw.states: \n",
    "        if state in gw.goals:\n",
    "            #new_values[state] = 0\n",
    "            pass\n",
    "        else:\n",
    "            \n",
    "            v = dict.fromkeys(gw.get_allowed_actions(state), 0.0) # inicializa vector de valores de estado v0(s)=0\n",
    "            \n",
    "            # definir estados finales para todas las accciones posibles ['N','S','E','W'] \n",
    "            \n",
    "            # accion Norte \n",
    "            N, reward, _, done = gw.step(state, 'N', random=False)\n",
    "            if N in gw.goals: # si estado final es terminal (goal)\n",
    "                NE=(N[0],N[1]+1) # estado con viento es estado final +1 a la derecha\n",
    "                if NE not in gw.states: # si estado con viento no esta en MDP\n",
    "                    NE=N # se queda en el mismo estado \n",
    "                else:\n",
    "                    pass\n",
    "            else:  # si estado final es no terminal\n",
    "                NE, reward, _, done = gw.step(N, 'E', random=False) # estado con viento es estado final dando un paso a la derecha\n",
    "                    \n",
    "            # accion Sur       \n",
    "            S, reward, _, done = gw.step(state, 'S', random=False)         \n",
    "            if S in gw.goals: # si estado final es terminal (goal)\n",
    "                SE=(S[0],S[1]+1)# estado con viento es estado final +1 a la derecha\n",
    "                if SE not in gw.states: # si estado con viento no esta en MDP\n",
    "                    SE=S # se queda en el mismo estado \n",
    "                else:\n",
    "                    pass\n",
    "            else: # si estado final es no terminal\n",
    "                SE, reward, _, done = gw.step(S, 'E', random=False) # estado con viento es estado final dando un paso a la derecha\n",
    "                \n",
    "            # accion East       \n",
    "            E, reward, _, done = gw.step(state, 'E', random=False)         \n",
    "            if E in gw.goals:\n",
    "                EE=(E[0],E[1]+1)\n",
    "                if EE not in gw.states:\n",
    "                    EE=E\n",
    "                else:\n",
    "                    pass\n",
    "            else: \n",
    "                EE, reward, _, done = gw.step(E, 'E', random=False)\n",
    "                \n",
    "            # accion Weast       \n",
    "            W, reward, _, done = gw.step(state, 'W', random=False)         \n",
    "            if W in gw.goals:\n",
    "                WE=(S[0],S[1]+1)\n",
    "                if WE not in gw.states:\n",
    "                    WE=W\n",
    "                else:\n",
    "                    pass\n",
    "            else: \n",
    "                WE, reward, _, done = gw.step(W, 'E', random=False)\n",
    "\n",
    "            # calcular v(s') para todas las acciones posibles  ['N','S','E','W'] \n",
    "            v['N']= gw.action_probabilities2[0]*(r_trans+gamma*gw.state_values[N])+gw.action_probabilities2[1]*(r_trans+gamma*gw.state_values[NE])\n",
    "            v['S']= gw.action_probabilities2[0]*(r_trans+gamma*gw.state_values[S])+gw.action_probabilities2[1]*(r_trans+gamma*gw.state_values[SE])\n",
    "            v['E']= gw.action_probabilities2[0]*(r_trans+gamma*gw.state_values[E])+gw.action_probabilities2[1]*(r_trans+gamma*gw.state_values[EE])\n",
    "            v['W']= gw.action_probabilities2[0]*(r_trans+gamma*gw.state_values[W])+gw.action_probabilities2[1]*(r_trans+gamma*gw.state_values[WE])\n",
    "            \n",
    "            # actualizar politica (accion) en estado state como la accion con el valor de estado v(s') máximo \n",
    "            # actualizar v(s) como el valor de estado v(s') máximo\n",
    "            gw.policy[state], new_values[state] = gw.key_max(v)\n",
    "            \n",
    "    gw.state_values = copy.deepcopy(new_values)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma=0.9\n",
    "H=30\n",
    "init_state=(3,0)\n",
    "gw.value_iteration = MethodType(value_iteration, gw)\n",
    "gw.solve_value_iteration(gamma=gamma, horizon=H, init_state=init_state )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
