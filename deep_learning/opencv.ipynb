{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# visualización \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuracion de graficas\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver Imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer imagen\n",
    "img = cv.imread(cv.samples.findFile(\"data/colibri.jpg\"))\n",
    "\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    "    \n",
    "# display imagen\n",
    "cv.imshow(\"Display window\", img)\n",
    "k = cv.waitKey(0)\n",
    "if k == ord(\"s\"):\n",
    "    cv.imwrite(\"data/starry_night.png\", img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar video\n",
    "cap = cv.VideoCapture('data/01.avi')\n",
    "while cap.isOpened(): # mientras cap este abierta\n",
    "    \n",
    "    # extraer frame (imagen), ret(flag)\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    #gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) # aplicar escala de grises\n",
    "    cv.imshow('frame', frame) # mostrar frame\n",
    "    \n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturar Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturar video\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# crear VideoWriter (guardar video)\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "# definir path para guardar video\n",
    "out = cv.VideoWriter('data/output.avi', fourcc, 20.0, (640,  480))\n",
    "while cap.isOpened(): # mientras la camara captura\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    #frame = cv.flip(frame, 0) # voltear video\n",
    "    # escribir cada frame\n",
    "    out.write(frame)\n",
    "    cv.imshow('frame', frame) # mostrar video capturado\n",
    "    \n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dibujar geometrias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dibujar geometrias\n",
    "\n",
    "# Create a black image\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "\n",
    "# dibujar linea azul\n",
    "cv.line(img,(0,0),(511,511),(255,0,0),5)\n",
    "# dibujar rectangulo verde\n",
    "cv.rectangle(img,(384,0),(510,128),(0,255,0),3)\n",
    "# dibujar circulo\n",
    "cv.circle(img,(447,63), 63, (0,0,255), -1)\n",
    "# dibujar elipse\n",
    "cv.ellipse(img,(256,256),(100,50),0,0,180,255,-1)\n",
    "# dibujar poligono\n",
    "pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv.polylines(img,[pts],True,(0,255,255))\n",
    "\n",
    "cv.imshow(\"Display window\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregar texto\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "cv.putText(img,'OpenCV',(10,500), font, 4,(255,255,255),2,cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver eventos de mouse\n",
    "events = [i for i in dir(cv) if 'EVENT' in i]\n",
    "print( events )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse callback\n",
    "\n",
    "# dibujar circulo\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    if event == cv.EVENT_LBUTTONDBLCLK: # clic izquierdo\n",
    "        cv.circle(img,(x,y),100,(255,0,0),-1)\n",
    "        \n",
    "# crear fondo negro\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv.namedWindow('image') # nombre de ventana\n",
    "cv.setMouseCallback('image',draw_circle)\n",
    "while(1):\n",
    "    cv.imshow('image',img)\n",
    "    if cv.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing = False # true si presiona el mouse\n",
    "mode = True # True, dibuja rectangulo. Press 'm' para curva\n",
    "ix,iy = -1,-1\n",
    "\n",
    "# funció mouse callback \n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global ix,iy,drawing,mode\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix,iy = x,y\n",
    "    elif event == cv.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            if mode == True:\n",
    "                cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "            else:\n",
    "                cv.circle(img,(x,y),5,(0,0,255),-1)\n",
    "    elif event == cv.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if mode == True:\n",
    "            cv.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "        else:\n",
    "            cv.circle(img,(x,y),5,(0,0,255),-1)\n",
    "            \n",
    "            \n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv.namedWindow('image') # nombre de ventana\n",
    "cv.setMouseCallback('image',draw_circle) # aplicar funcion callback\n",
    "while(1):\n",
    "    cv.imshow('image',img)\n",
    "    k = cv.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trackbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear trackbar: \n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# crear fondo negro en ventana\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv.namedWindow('image') # nombre de ventana\n",
    "\n",
    "# crear barras de color RGB\n",
    "cv.createTrackbar('R','image',0,255,nothing)\n",
    "cv.createTrackbar('G','image',0,255,nothing)\n",
    "cv.createTrackbar('B','image',0,255,nothing)\n",
    "# create switch for ON/OFF functionality\n",
    "\n",
    "# crear switch ON/OFF\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "# crear Trackbar\n",
    "cv.createTrackbar(switch, 'image',0,1,nothing)\n",
    "while(1):\n",
    "    cv.imshow('image',img) # mostrar imagen\n",
    "    k = cv.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    # extraer posicion de 4 trackbars\n",
    "    r = cv.getTrackbarPos('R','image')\n",
    "    g = cv.getTrackbarPos('G','image')\n",
    "    b = cv.getTrackbarPos('B','image')\n",
    "    s = cv.getTrackbarPos(switch,'image')\n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagen a color\n",
    "img = cv.imread('data/lemon.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificar pixel (casilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraer pixel por coordenadas x,y (fila,columna)\n",
    "# retorna array de formato de pixel (RGB)\n",
    "pixel = img[100,100]\n",
    "pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azul = img[100,100,0] #pixel azul\n",
    "azul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiar valor de pixel\n",
    "img[100,100] = [255,255,255] # cambiar (color) de pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acceder a valor RED de pixel\n",
    "img.item(10,10,2)\n",
    "\n",
    "# modificar valor RED de pixel \n",
    "img.itemset((10,10,2), 100) # valor RED de pixel a modificar, nuevo valor\n",
    "img.item(10,10,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades de Imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraer propiedades de imagen\n",
    "\n",
    "# filas, columnas, canales\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numero de pixeles (casillas en matriz)\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipo de imagen\n",
    "img.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagen de Messi\n",
    "img = cv.imread('data/messi.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraer bola de imagen\n",
    "ball = img[280:340, 330:390] \n",
    "# copiar bola en otra parte de la imagen\n",
    "img[273:333, 100:160] = ball\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging/Indexing sobre canales de Imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dividir imagen en canales individuales\n",
    "b,g,r = cv.split(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unir canales BGR de imagen\n",
    "img = cv.merge((b,g,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = img[:,:,0] # indexing por canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:,:,2] = 0 # cambiar pixeles rojos (canal rojo) a 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar Bordes de Imagenes (Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hacer bordes para imagenes (Padding)\n",
    "\n",
    "\n",
    "BLUE = [255,0,0]\n",
    "img1 = cv.imread('data/opencv-logo.png')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "# aplicar funciones de bordes sobre imagen\n",
    "replicate = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REPLICATE)\n",
    "reflect = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT)\n",
    "reflect101 = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_REFLECT_101)\n",
    "wrap = cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_WRAP)\n",
    "constant= cv.copyMakeBorder(img1,10,10,10,10,cv.BORDER_CONSTANT,value=BLUE)\n",
    "\n",
    "# Plot\n",
    "plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n",
    "plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n",
    "plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n",
    "plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n",
    "plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n",
    "plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones Aritmeticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.uint8([250])\n",
    "y = np.uint8([10])\n",
    "\n",
    "# sumar\n",
    "cv.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $dst=α⋅img1+β⋅img2+γ$\n",
    "# Here γ is taken as zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Blendig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('data/messi.jpg')\n",
    "img2 = cv.imread('data/colibri.jpg')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "assert img2 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "# \n",
    "dst = cv.addWeighted(img1,0.7,img2,0.3,0)\n",
    "cv.imshow('dst',dst)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitwise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cargar imagenes \n",
    "img1 = cv.imread('data/messi.jpg')\n",
    "img2 = cv.imread('data/colibri.jpg')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "assert img2 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "\n",
    "# extraer propiedades de imagen\n",
    "rows,cols,channels = img2.shape\n",
    "# crear ROI\n",
    "roi = img1[0:rows, 0:cols]\n",
    "\n",
    "# crear mascara gris \n",
    "img2gray = cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
    "ret, mask = cv.threshold(img2gray, 10, 255, cv.THRESH_BINARY)\n",
    "mask_inv = cv.bitwise_not(mask) # mascara inversa\n",
    "\n",
    "# sombrear area de logo\n",
    "img1_bg = cv.bitwise_and(roi,roi,mask = mask_inv)\n",
    "# Take only region of logo from logo image.\n",
    "img2_fg = cv.bitwise_and(img2,img2,mask = mask)\n",
    "# Put logo in ROI and modify the main image\n",
    "dst = cv.add(img1_bg,img2_fg)\n",
    "img1[0:rows, 0:cols ] = dst\n",
    "cv.imshow('res',img1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance y Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = cv.getTickCount()\n",
    "# your code execution\n",
    "e2 = cv.getTickCount()\n",
    "time = (e2 - e1)/ cv.getTickFrequency()\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagen\n",
    "img1 = cv.imread('data/messi.jpg')\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "e1 = cv.getTickCount()\n",
    "for i in range(5,49,2):\n",
    "    img1 = cv.medianBlur(img1,i)\n",
    "e2 = cv.getTickCount()\n",
    "t = (e2 - e1)/cv.getTickFrequency()\n",
    "print( t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.useOptimized()\n",
    "%time res = cv.medianBlur(img, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.setUseOptimized(False)\n",
    "cv.useOptimized()\n",
    "%timeit res = cv.medianBlur(img,49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de espacios de colores \n",
    "flags = [i for i in dir(cv) if i.startswith('COLOR_')]\n",
    "flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar Espacio de Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiar espacio de color de imagen\n",
    "# parametros: imagen, flag de conversion\n",
    "cv.cvtColor(img, cv.COLOR_BGR2GRAY) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Tracking\n",
    "\n",
    "# capturar video\n",
    "cap = cv.VideoCapture(0)\n",
    "while(1):\n",
    "    \n",
    "    # extraer cada frame\n",
    "    _, frame = cap.read()\n",
    "    # Convert BGR to HSV\n",
    "    # convetir cada frame a espacio de color HSV\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    \n",
    "    # definir rangos de color azul en  espacio de color HSV\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    "    \n",
    "    \n",
    "    # crear mascara en el rango de color azul definido\n",
    "    mask = cv.inRange(hsv, lower_blue, upper_blue)    \n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv.bitwise_and(frame,frame, mask= mask)\n",
    "    \n",
    "    cv.imshow('frame',frame)\n",
    "    cv.imshow('mask',mask)\n",
    "    cv.imshow('res',res)\n",
    "    k = cv.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores de espacios de color\n",
    "green = np.uint8([[[0,255,0 ]]])\n",
    "hsv_green = cv.cvtColor(green,cv.COLOR_BGR2HSV)\n",
    "green\n",
    "# valores de color verde  HSV\n",
    "hsv_green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('data/messi.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "cv.imshow('image',img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing (cambiar tamaño)\n",
    " Metodos de interpolación\n",
    " \n",
    " * default: cv.INTER_LINEAR \n",
    " * escogimiento: cv.INTER_AREA\n",
    " * zoom: cv.INTER_CUBIC, cv.INTER_LINEAR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing\n",
    "# cambiar tamaño de la imagen\n",
    "# factor de escala: fx,fy\n",
    "\n",
    "# metodos de interpolación\n",
    "# default: cv.INTER_LINEAR \n",
    "# escogimiento: cv.INTER_AREA\n",
    "# zoom: cv.INTER_CUBIC, cv.INTER_LINEAR \n",
    "\n",
    "res = cv.resize(img,None,fx=2, fy=2, interpolation = cv.INTER_CUBIC)\n",
    "cv.imshow('image',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraer altura, ancho de imagen\n",
    "# extraer las caracteristicas excepto el canal\n",
    "height, width = img.shape[:2]\n",
    "# escalar imagen por un factor de 2 de altura y 2 de ancho\n",
    "res = cv.resize(img,(2*width, 2*height), interpolation = cv.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traslación\n",
    "\n",
    "Matriz de Transformacion(Traslacion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cargar imagen\n",
    "# cambiar a escala de gris\n",
    "img = cv.imread('data/messi.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "# extraer tamaño de imagen - matriz(filas, columnas)\n",
    "rows,cols = img.shape\n",
    "\n",
    "# crear  matriz de traslacion (transformacion)\n",
    "M = np.float32([[1,0,100],[0,1,50]])\n",
    "\n",
    "# aplicar transformacion\n",
    "# parametros: imagen, matriz de traslacion, tamaño de la imagen\n",
    "# imagen, matriz, (width, height) de salida\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "cv.imshow('img',dst) # mostrar imagen\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagen\n",
    "# cambiar a escala de gris\n",
    "img = cv.imread('data/messi.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "# extraer tamaño de imagen (matriz)\n",
    "rows,cols = img.shape\n",
    "# cols-1 and rows-1 are the coordinate limits\n",
    "# crear matriz de rotacion\n",
    "M = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1)\n",
    "# rotar imagen 90°\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "cv.imshow('img',dst) # mostrar imagen\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagen\n",
    "img = cv.imread('data/messi.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "# extraer dimensiones de imagen\n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "# definir puntos para la transformacion\n",
    "pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "\n",
    "# crear matriz de transformacion affine\n",
    "M = cv.getAffineTransform(pts1,pts2)\n",
    "# aplicar transformacion\n",
    "dst = cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "# plot\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagen\n",
    "img = cv.imread('data/colibri.jpg')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "# extraer dimensiones de imagen \n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "# definir puntos de transformacion\n",
    "pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "\n",
    "# matriz de transformacion\n",
    "M = cv.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "# aplicar transformacion\n",
    "dst = cv.warpPerspective(img,M,(300,300))\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***FALTA TERMINAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harris Corner Detection\n",
    "\n",
    "* img: Input image en escala de gris, float32 type\n",
    "* blockSize: Tamaño de vecindario para detección de esquinas\n",
    "* ksize: Parametro de apertura (Sobel derivative)\n",
    "* k: Harris detector free parameter\n",
    "\n",
    "Función objetivo:\n",
    "\n",
    "$R=λ_1λ_2−k(λ_1+λ_2)^2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cargar imagen\n",
    "img = cv.imread('data/chess.png')\n",
    "# cambiar imagen a escala de gris\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "# extraer escala de gris\n",
    "gray = np.float32(gray)\n",
    "\n",
    "# aplicar detección Harris Corner \n",
    "dst = cv.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "# dilatar para mostrar esquinas\n",
    "dst = cv.dilate(dst,None)\n",
    "\n",
    "# umbral para valor optimo\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "# mostar imagen\n",
    "cv.imshow('dst',img)\n",
    "if cv.waitKey(0) & 0xff == 27:\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detección Harris Corner con subpixel accuracy\n",
    "\n",
    "# cargar imagen\n",
    "img = cv.imread('data/chess.png')\n",
    "# cambiar a escala de gris \n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# find Harris corners\n",
    "# extraer escala de grises de matriz\n",
    "gray = np.float32(gray)\n",
    "# aplicar detección Harris Corner \n",
    "dst = cv.cornerHarris(gray,2,3,0.04)\n",
    "# dilatar resultado\n",
    "dst = cv.dilate(dst,None)\n",
    "\n",
    "# aplicar umbral\n",
    "ret, dst = cv.threshold(dst,0.01*dst.max(),255,0)\n",
    "dst = np.uint8(dst)\n",
    "\n",
    "# extraer centroides\n",
    "ret, labels, stats, centroids = cv.connectedComponentsWithStats(dst)\n",
    "# definir criterio de parada y refinar esquinas\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "corners = cv.cornerSubPix(gray,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "# dibujar centroides\n",
    "res = np.hstack((centroids,corners))\n",
    "res = np.int0(res)\n",
    "img[res[:,1],res[:,0]]=[0,0,255]\n",
    "img[res[:,3],res[:,2]] = [0,255,0]\n",
    "cv.imwrite('subpixel5.png',img)\n",
    "\n",
    "# mostar imagen\n",
    "cv.imshow('Harris Corner con subpixel accuracy',res)\n",
    "if cv.waitKey(0) & 0xff == 27:\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shi-Tomasi Corner Detection\n",
    "\n",
    "Función objetivo:\n",
    "\n",
    "$R=min(λ1,λ2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cargar imagen\n",
    "img = cv.imread('data/chess.png')\n",
    "\n",
    "# cambiar a escala de gris\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# aplicar detección Shi-Tomasi \n",
    "# imagen(escala de gris), numero de esquinas, , \n",
    "corners = cv.goodFeaturesToTrack(gray,25,0.01,10)\n",
    "\n",
    "# convertir top esquinas a numpy array\n",
    "corners = np.int0(corners)\n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv.circle(img,(x,y),3,255,-1)\n",
    "plt.imshow(img),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT (Scale-Invariant Feature Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagen\n",
    "img = cv.imread('data/water_tower.jpg')\n",
    "# cambiar a escala de gris\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# crear objeto SIFT\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "# detectar keypoints (features-patrones) de la imagen en escala de gris\n",
    "kp = sift.detect(gray,None)\n",
    "\n",
    "# dibujar keypoints\n",
    "img=cv.drawKeypoints(gray,kp,img)\n",
    "# dibujar keypoints con significancia y orientacion\n",
    "img=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv.imwrite('sift_keypoints.jpg',img)\n",
    "\n",
    "# calcular descriptores\n",
    "kp,des = sift.compute(gray,kp)\n",
    "kp, des = sift.detectAndCompute(gray,None)\n",
    "\n",
    "# mostar imagen\n",
    "cv.imshow('sift_keypoints',img)\n",
    "if cv.waitKey(0) & 0xff == 27:\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SURF (Speeded-Up Robust Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagen \n",
    "# cambiar a escala de gris\n",
    "img = cv.imread('data/water_tower.jpg', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# crear objeto SURF\n",
    "# Hessian Threshold = 400, value 300-500\n",
    "surf = cv.xfeatures2d.SURF_create(400)\n",
    "\n",
    "# detectar keypoints (features-patrones) de la imagen \n",
    "kp, des = surf.detectAndCompute(img,None)\n",
    "\n",
    "img2 = cv.drawKeypoints(img,kp,None,(255,0,0),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cargar imagen\n",
    "# convetir a escala de gris\n",
    "img = cv.imread('data/water_tower.jpg', cv.IMREAD_GRAYSCALE) # `<opencv_root>/samples/data/blox.jpg`\n",
    "\n",
    "# crear objeto FAST\n",
    "# parametros default\n",
    "fast = cv.FastFeatureDetector_create()\n",
    "\n",
    "\n",
    "# extraer keypoints \n",
    "kp = fast.detect(img,None)\n",
    "# dibujar keypoints\n",
    "img2 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n",
    "\n",
    "\n",
    "# mostrar parametros de FAST \n",
    "# parametros: Threshold, nonmaxSuppression, neighborhood, Total Keypoints with nonmaxSuppression\n",
    "print( \"Threshold: {}\".format(fast.getThreshold()) )\n",
    "print( \"nonmaxSuppression:{}\".format(fast.getNonmaxSuppression()) )\n",
    "print( \"neighborhood: {}\".format(fast.getType()) )\n",
    "print( \"Total Keypoints with nonmaxSuppression: {}\".format(len(kp)) )\n",
    "\n",
    "# aplicar FAST a imagen\n",
    "cv.imwrite('fast_true.png', img2)\n",
    "\n",
    "\n",
    "# quitar nonmaxSuppression\n",
    "fast.setNonmaxSuppression(0)\n",
    "kp = fast.detect(img, None)\n",
    "print( \"Total Keypoints without nonmaxSuppression: {}\".format(len(kp)) )\n",
    "\n",
    "# quitar nonmaxSuppression a Imagen\n",
    "img3 = cv.drawKeypoints(img, kp, None, color=(255,0,0))\n",
    "cv.imwrite('fast_false.png', img3)\n",
    "\n",
    "\n",
    "# mostar imagen\n",
    "\n",
    "plt.subplot(131),plt.imshow(img) ,plt.title('Input')\n",
    "plt.subplot(132),plt.imshow(img2),plt.title('Output')\n",
    "plt.subplot(133),plt.imshow(img3),plt.title('Output')\n",
    "\n",
    "plt.show()\n",
    "if cv.waitKey(0) & 0xff == 27:\n",
    "    cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRIEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cargar imagen \n",
    "# cambiar a escala de gris\n",
    "img = cv.imread('data/water_tower.jpg', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Initiate FAST detector\n",
    "star = cv.xfeatures2d.StarDetector_create()\n",
    "# Initiate BRIEF extractor\n",
    "brief = cv.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "# find the keypoints with STAR\n",
    "kp = star.detect(img,None)\n",
    "# compute the descriptors with BRIEF\n",
    "kp, des = brief.compute(img, kp)\n",
    "print( brief.descriptorSize() )\n",
    "print( des.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagen\n",
    "# cambiar escala a gris\n",
    "img = cv.imread('data/viaduct.jpg', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# crear ORB detector de patrones\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "# extraer keypoints \n",
    "kp = orb.detect(img,None)\n",
    "\n",
    "# calcular descriptores de keypoints \n",
    "kp, des = orb.compute(img, kp)\n",
    "\n",
    "# dibujar keypoints, sin tamaño ni orientacion\n",
    "img2 = cv.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img2), plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brute-Force Matcher\n",
    "\n",
    "\n",
    "Matcher : \n",
    "\n",
    "* DMatch.distance - Distancia entre descriptores, mejor es 0\n",
    "* DMatch.trainIdx - Indice de descriptor de entrenamiento\n",
    "* DMatch.queryIdx - Indice de descriptor en query\n",
    "* DMatch.imgIdx - Indice de imagen de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagenes para comparar\n",
    "img1 = cv.imread('data/fight1.jpg',cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "img2 = cv.imread('data/fight2.jpg',cv.IMREAD_GRAYSCALE) # trainImage\n",
    "\n",
    "# crear ORB detector\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "# extraer  keypoints \n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "# crear BFMatcher \n",
    "# descriptores binarios: NORM_HAMMING \n",
    "bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "\n",
    "# match de descriptores entre imagenes\n",
    "matches = bf.match(des1,des2)\n",
    "\n",
    "# sort por distancia\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "# dibujar 10 top matches\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,matches[:10],None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagenes para hacer match \n",
    "# cambiar a escala de gris\n",
    "img1 = cv.imread('data/fight1.jpg',cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "img2 = cv.imread('data/fight2.jpg',cv.IMREAD_GRAYSCALE) # trainImage\n",
    "\n",
    "# crear SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "# extraer  keypoints y descriptores\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "# crear BFMatcher\n",
    "bf = cv.BFMatcher()\n",
    "\n",
    "# match de descriptores entre imagenes\n",
    "matches = bf.knnMatch(des1,des2,k=2)\n",
    "# aplicar ratio test\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75*n.distance:\n",
    "        good.append([m])\n",
    "        \n",
    "# cv.drawMatchesKnn expects list of lists as matches.\n",
    "# dibujar KNN matches\n",
    "img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLANN based Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros de FLANN \n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                   table_number = 6, # 12\n",
    "                   key_size = 12,     # 20\n",
    "                   multi_probe_level = 1) #2\n",
    "\n",
    "# cargar imagenes en escala de gris\n",
    "img1 = cv.imread('data/fight1.jpg',cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "img2 = cv.imread('data/fight2.jpg',cv.IMREAD_GRAYSCALE) # trainImage\n",
    "\n",
    "# crear SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "# extraer keypoints y descriptors\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "# definir parametro  FLANN\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "\n",
    "\n",
    "# crear FlannBasedMatcher\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "# parametros: index_params, search_params\n",
    "flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "\n",
    "\n",
    "# match de descriptores entre imagenes\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "# crear mascara para mejores matches\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "# aplicar ratio test per Lowe's paper\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "img3 = cv.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)\n",
    "plt.imshow(img3,),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Matching + Homografía para encontrar objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "# cargar imagenes en escala de gris \n",
    "img1 = cv.imread('data/chess.png', cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "img2 = cv.imread('data/chess2.png', cv.IMREAD_GRAYSCALE) # trainImage\n",
    "\n",
    "# crear SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "# extraer keypoints y  descriptores\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "# definir parametros de FlannBasedMatcher (diccionarios) \n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "\n",
    "# crear matcher FlannBasedMatcher\n",
    "flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# extraer matches a partir de descriptores\n",
    "# KNN=2 vecinos\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "# aplicar ratio test per Lowe's paper\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si hay suficentes matches entre imagenes\n",
    "if len(good)>MIN_MATCH_COUNT:\n",
    "    \n",
    "    # extraer posiciones de los matches en keypoints x,y \n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    \n",
    "    # matriz de transformación\n",
    "    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "    \n",
    "    # aplicar transformación\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    h,w = img1.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv.perspectiveTransform(pts,M)\n",
    "    img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n",
    "else:\n",
    "    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "    matchesMask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dibujar parametro \n",
    "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    "# dibujar matches\n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "plt.imshow(img3, 'gray'),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Capturar Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturar video\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# crear VideoWriter (guardar video)\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "# definir path para guardar video\n",
    "# crear VideoWriter(path)\n",
    "out = cv.VideoWriter('data/output.avi', fourcc, 20.0, (640,  480))\n",
    "while cap.isOpened(): # mientras la camara captura\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    #frame = cv.flip(frame, 0) # voltear video\n",
    "    # escribir cada frame\n",
    "    out.write(frame)\n",
    "    cv.imshow('frame', frame) # mostrar video capturado\n",
    "    \n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducir Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cargar video: capturar video\n",
    "# parametro:  path de video\n",
    "cap = cv.VideoCapture('data/01.avi')\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # ret: flag de capturar video\n",
    "    # frame: frame actual (imagen)\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret: # if frame is read correctly ret is True\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # cambiar frame(imagen) a escala de gris\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # mostrar frame\n",
    "    cv.imshow('frame', gray)\n",
    "    \n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background Subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstrucción 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de Objetos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
